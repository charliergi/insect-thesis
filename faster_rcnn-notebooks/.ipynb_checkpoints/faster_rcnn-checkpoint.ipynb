{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # TLT FasterRCNN example usecase\n",
    "\n",
    " This notebook shows an example usecase of FasterRCNN using Transfer Learning Toolkit.\n",
    "\n",
    " 0. [Set up env variables](#head-0)\n",
    " 1. [Prepare dataset and pretrained model](#head-1)<br>\n",
    "     1.1 [Prepare tfrecords from kitti format dataset](#head-1-1)<br>\n",
    "     1.2 [Download pretrained model](#head-1-2)\n",
    " 2. [Provide training specification](#head-2)\n",
    " 3. [Run TLT training](#head-3)\n",
    " 4. [Evaluate trained models](#head-4)\n",
    " 5. [Prune trained models](#head-5)\n",
    " 6. [Retrain pruned models](#head-6)\n",
    " 7. [Evaluate retrained model](#head-7)\n",
    " 8. [Visualize inferences](#head-8)\n",
    " 9. [Deploy](#head-9)\n",
    " 10. [QAT workflow](#head-10)<br>\n",
    "     10.1 [Training](#head-10.1)<br>\n",
    "     10.2 [Evaluation](#head-10.2)<br>\n",
    "     10.3 [Pruning](#head-10.3)<br>\n",
    "     10.4 [Retraining](#head-10.4)<br>\n",
    "     10.5 [Evaluation of the retrained model](#head-10.5)<br>\n",
    "     10.6 [Inference of the retrained model](#head-10.6)<br>\n",
    "     10.7 [Deployment of the QAT model](#head-10.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 0. Set up env variables <a class=\"anchor\" id=\"head-0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please replace the variables with your own.\n",
      "env: GPU_INDEX=0\n",
      "env: KEY=tlt\n",
      "env: USER_EXPERIMENT_DIR=/workspace/tlt-experiments/insect-thesis\n",
      "env: DATA_DOWNLOAD_DIR=/workspace/tlt-experiments/insect-thesis/data\n",
      "env: SPECS_DIR=./specs\n"
     ]
    }
   ],
   "source": [
    "# Setting up env variables for cleaner command line commands.\n",
    "print(\"Please replace the variables with your own.\")\n",
    "%env GPU_INDEX=0\n",
    "%env KEY=tlt\n",
    "%env USER_EXPERIMENT_DIR=/workspace/tlt-experiments/insect-thesis\n",
    "%env DATA_DOWNLOAD_DIR=/workspace/tlt-experiments/insect-thesis/data\n",
    "%env SPECS_DIR=./specs\n",
    "!mkdir -p $DATA_DOWNLOAD_DIR/faster_rcnn\n",
    "# Prepend current directory and HOME directory to the PATH env variable.\n",
    "import os\n",
    "os.environ['PATH'] = './:' + os.environ.get('HOME', '') + ':' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Prepare dataset and pretrained model <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will be using the KITTI detection dataset for the tutorial. To find more details please visit\n",
    " http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d. Please download the KITTI detection images (http://www.cvlibs.net/download.php?file=data_object_image_2.zip) and labels (http://www.cvlibs.net/download.php?file=data_object_label_2.zip) to $DATA_DOWNLOAD_DIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset is present\n",
    "#!mkdir -p $DATA_DOWNLOAD_DIR\n",
    "#!if [ ! -f $DATA_DOWNLOAD_DIR/data_object_image_2.zip ]; then echo 'Image zip file not found, please download.'; else echo 'Found Image zip file.';fi\n",
    "#!if [ ! -f $DATA_DOWNLOAD_DIR/data_object_label_2.zip ]; then echo 'Label zip file not found, please download.'; else echo 'Found Labels zip file.';fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack \n",
    "#!unzip -u $DATA_DOWNLOAD_DIR/data_object_image_2.zip -d $DATA_DOWNLOAD_DIR\n",
    "#!unzip -u $DATA_DOWNLOAD_DIR/data_object_label_2.zip -d $DATA_DOWNLOAD_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxrwxrwx 4 root root 4096 Mar 22 15:40 faster_rcnn\r\n",
      "drwxrwxrwx 3 root root 4096 Mar 22 10:04 kitti\r\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "!ls -l $DATA_DOWNLOAD_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, if you have your own dataset already in a volume (or folder), you can mount the volume on `DATA_DOWNLOAD_DIR` (or create a soft link). Below shows an example:\n",
    "```bash\n",
    "# if your dataset is in /dev/sdc1\n",
    "mount /dev/sdc1 $DATA_DOWNLOAD_DIR\n",
    "\n",
    "# if your dataset is in folder /var/dataset\n",
    "ln -sf /var/dataset $DATA_DOWNLOAD_DIR\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare tfrecords from kitti format dataset <a class=\"anchor\" id=\"head-1-1\"></a>\n",
    "\n",
    "* Update the tfrecords spec file to take in your kitti format dataset\n",
    "* Create the tfrecords using the dataset_convert \n",
    "* TFRecords only need to be generated once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFrecords conversion spec file for training\n",
      "kitti_config {\r\n",
      "  root_directory_path: \"/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/train\"\r\n",
      "  image_dir_name: \"images\"\r\n",
      "  label_dir_name: \"labels\"\r\n",
      "  image_extension: \".jpg\"\r\n",
      "  partition_mode: \"random\"\r\n",
      "  num_partitions: 2\r\n",
      "  val_split: 14\r\n",
      "  num_shards: 10\r\n",
      "}\r\n",
      "image_directory_path: \"/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/train\"\r\n"
     ]
    }
   ],
   "source": [
    "print(\"TFrecords conversion spec file for training\")\n",
    "!cat $SPECS_DIR/frcnn_tfrecords_kitti_trainval_custom.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "2021-03-22 15:43:12,268 - iva.detectnet_v2.dataio.build_converter - INFO - Instantiating a kitti converter\n",
      "2021-03-22 15:43:12,268 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Creating output directory /workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/tfrecords/kitti_trainval\n",
      "2021-03-22 15:43:12,296 - iva.detectnet_v2.dataio.kitti_converter_lib - INFO - Num images in\n",
      "Train: 861\tVal: 140\n",
      "2021-03-22 15:43:12,296 - iva.detectnet_v2.dataio.kitti_converter_lib - INFO - Validation data in partition 0. Hence, while choosing the validationset during training choose validation_fold 0.\n",
      "2021-03-22 15:43:12,297 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 0\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/detectnet_v2/dataio/dataset_converter_lib.py:142: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "2021-03-22 15:43:12,297 - tensorflow - WARNING - From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/detectnet_v2/dataio/dataset_converter_lib.py:142: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/iva/detectnet_v2/dataio/kitti_converter_lib.py:273: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "2021-03-22 15:43:12,324 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 1\n",
      "2021-03-22 15:43:12,336 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 2\n",
      "2021-03-22 15:43:12,347 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 3\n",
      "2021-03-22 15:43:12,359 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 4\n",
      "2021-03-22 15:43:12,372 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 5\n",
      "2021-03-22 15:43:12,385 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 6\n",
      "2021-03-22 15:43:12,396 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 7\n",
      "2021-03-22 15:43:12,407 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 8\n",
      "2021-03-22 15:43:12,419 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 9\n",
      "2021-03-22 15:43:12,431 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'noctuidae': 142\n",
      "\n",
      "2021-03-22 15:43:12,431 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 0\n",
      "2021-03-22 15:43:12,501 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 1\n",
      "2021-03-22 15:43:12,569 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 2\n",
      "2021-03-22 15:43:12,633 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 3\n",
      "2021-03-22 15:43:12,697 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 4\n",
      "2021-03-22 15:43:12,764 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 5\n",
      "2021-03-22 15:43:12,829 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 6\n",
      "2021-03-22 15:43:12,899 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 7\n",
      "2021-03-22 15:43:12,963 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 8\n",
      "2021-03-22 15:43:13,030 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 9\n",
      "2021-03-22 15:43:13,098 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'noctuidae': 870\n",
      "\n",
      "2021-03-22 15:43:13,098 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Cumulative object statistics\n",
      "2021-03-22 15:43:13,098 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'noctuidae': 1012\n",
      "\n",
      "2021-03-22 15:43:13,099 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Class map. \n",
      "Label in GT: Label in tfrecords file \n",
      "b'noctuidae': b'noctuidae'\n",
      "For the dataset_config in the experiment_spec, please use labels in the tfrecords file, while writing the classmap.\n",
      "\n",
      "2021-03-22 15:43:13,099 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Tfrecords generation complete.\n"
     ]
    }
   ],
   "source": [
    "# Creating a new directory for the output tfrecords dump.\n",
    "!mkdir -p $USER_EXPERIMENT_DIR/tfrecords\n",
    "#KITTI trainval\n",
    "!faster_rcnn dataset_convert --gpu_index $GPU_INDEX -d $SPECS_DIR/frcnn_tfrecords_kitti_trainval_custom.txt \\\n",
    "                     -o $USER_EXPERIMENT_DIR/data/kitti/noctuidae/tfrecords/kitti_trainval/kitti_trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 644\r\n",
      "-rw-r--r-- 1 root root  8653 Mar 22 15:43 kitti_trainval-fold-000-of-002-shard-00000-of-00010\r\n",
      "-rw-r--r-- 1 root root  8584 Mar 22 15:43 kitti_trainval-fold-000-of-002-shard-00001-of-00010\r\n",
      "-rw-r--r-- 1 root root  8587 Mar 22 15:43 kitti_trainval-fold-000-of-002-shard-00002-of-00010\r\n",
      "-rw-r--r-- 1 root root  8589 Mar 22 15:43 kitti_trainval-fold-000-of-002-shard-00003-of-00010\r\n",
      "-rw-r--r-- 1 root root  8591 Mar 22 15:43 kitti_trainval-fold-000-of-002-shard-00004-of-00010\r\n",
      "-rw-r--r-- 1 root root  8588 Mar 22 15:43 kitti_trainval-fold-000-of-002-shard-00005-of-00010\r\n",
      "-rw-r--r-- 1 root root  8587 Mar 22 15:43 kitti_trainval-fold-000-of-002-shard-00006-of-00010\r\n",
      "-rw-r--r-- 1 root root  8650 Mar 22 15:43 kitti_trainval-fold-000-of-002-shard-00007-of-00010\r\n",
      "-rw-r--r-- 1 root root  8592 Mar 22 15:43 kitti_trainval-fold-000-of-002-shard-00008-of-00010\r\n",
      "-rw-r--r-- 1 root root  8589 Mar 22 15:43 kitti_trainval-fold-000-of-002-shard-00009-of-00010\r\n",
      "-rw-r--r-- 1 root root 52765 Mar 22 15:43 kitti_trainval-fold-001-of-002-shard-00000-of-00010\r\n",
      "-rw-r--r-- 1 root root 52756 Mar 22 15:43 kitti_trainval-fold-001-of-002-shard-00001-of-00010\r\n",
      "-rw-r--r-- 1 root root 52875 Mar 22 15:43 kitti_trainval-fold-001-of-002-shard-00002-of-00010\r\n",
      "-rw-r--r-- 1 root root 52815 Mar 22 15:43 kitti_trainval-fold-001-of-002-shard-00003-of-00010\r\n",
      "-rw-r--r-- 1 root root 52883 Mar 22 15:43 kitti_trainval-fold-001-of-002-shard-00004-of-00010\r\n",
      "-rw-r--r-- 1 root root 52737 Mar 22 15:43 kitti_trainval-fold-001-of-002-shard-00005-of-00010\r\n",
      "-rw-r--r-- 1 root root 52759 Mar 22 15:43 kitti_trainval-fold-001-of-002-shard-00006-of-00010\r\n",
      "-rw-r--r-- 1 root root 52824 Mar 22 15:43 kitti_trainval-fold-001-of-002-shard-00007-of-00010\r\n",
      "-rw-r--r-- 1 root root 52951 Mar 22 15:43 kitti_trainval-fold-001-of-002-shard-00008-of-00010\r\n",
      "-rw-r--r-- 1 root root 53370 Mar 22 15:43 kitti_trainval-fold-001-of-002-shard-00009-of-00010\r\n"
     ]
    }
   ],
   "source": [
    "!ls -rlt $USER_EXPERIMENT_DIR/data/kitti/noctuidae/tfrecords/kitti_trainval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.2 Download pre-trained model <a class=\"anchor\" id=\"head-1-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+---------+---------+---------+---------+\r\n",
      "| Name    | Reposit | Latest  | Applica | Framewo | Precisi | Last Mo | Permiss |\r\n",
      "|         | ory     | Version | tion    | rk      | on      | dified  | ion     |\r\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+\r\n",
      "| TLT Pre | nvidia/ | cspdark | Object  | Transfe | FP32    | Feb 25, | unlocke |\r\n",
      "| trained | tlt_pre | net19   | Detecti | r Learn |         | 2021    | d       |\r\n",
      "| Object  | trained |         | on      | ing     |         |         |         |\r\n",
      "| Detecti | _object |         |         | Toolkit |         |         |         |\r\n",
      "| on      | _detect |         |         |         |         |         |         |\r\n",
      "|         | ion     |         |         |         |         |         |         |\r\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+\r\n"
     ]
    }
   ],
   "source": [
    "!ngc registry model list nvidia/tlt_pretrained_object_detection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "# Download model from NGC.\n",
    "!ngc registry model download-version nvidia/tlt_pretrained_object_detection:resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'tlt_pretrained_object_detection_vdarknet19': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls tlt_pretrained_object_detection_vdarknet19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat 'tlt_pretrained_object_detection_vdarknet19/darknet_19.hdf5': No such file or directory\n",
      "total 2853800\n",
      "-rwxrwxrwx 1 root root  93278448 Mar 20 13:11 resnet_18.hdf5\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:39 frcnn_kitti_resnet18.epoch2.tlt\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:40 frcnn_kitti_resnet18.epoch3.tlt\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:41 frcnn_kitti_resnet18.epoch4.tlt\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:43 frcnn_kitti_resnet18.epoch5.tlt\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:44 frcnn_kitti_resnet18.epoch6.tlt\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:45 frcnn_kitti_resnet18.epoch7.tlt\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:47 frcnn_kitti_resnet18.epoch8.tlt\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:48 frcnn_kitti_resnet18.epoch9.tlt\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:49 frcnn_kitti_resnet18.epoch10.tlt\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:51 frcnn_kitti_resnet18.epoch11.tlt\n",
      "-rw-r--r-- 1 root root 101571600 Mar 20 13:52 frcnn_kitti_resnet18.epoch12.tlt\n",
      "-rw-r--r-- 1 root root  51196176 Mar 20 13:55 model_1_pruned.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:15 frcnn_kitti_resnet18_retrain.epoch1.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:17 frcnn_kitti_resnet18_retrain.epoch2.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:18 frcnn_kitti_resnet18_retrain.epoch3.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:19 frcnn_kitti_resnet18_retrain.epoch4.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:21 frcnn_kitti_resnet18_retrain.epoch5.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:22 frcnn_kitti_resnet18_retrain.epoch6.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:23 frcnn_kitti_resnet18_retrain.epoch7.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:24 frcnn_kitti_resnet18_retrain.epoch8.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:26 frcnn_kitti_resnet18_retrain.epoch9.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:27 frcnn_kitti_resnet18_retrain.epoch10.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:29 frcnn_kitti_resnet18_retrain.epoch11.tlt\n",
      "-rw-r--r-- 1 root root 101522856 Mar 20 14:30 frcnn_kitti_resnet18_retrain.epoch12.tlt\n",
      "drwxr-xr-x 2 root root     32768 Mar 20 14:37 inference_results_imgs_retrain\n",
      "drwxr-xr-x 2 root root     28672 Mar 20 14:37 inference_dump_labels_retrain\n",
      "-rw-r--r-- 1 root root 101703112 Mar 20 14:54 frcnn_kitti_resnet18.epoch1.tlt\n",
      "-rw------- 1 root root 160242408 Mar 21 13:58 darknet_19.hdf5\n",
      "-rw-r--r-- 1 root root 180216904 Mar 21 14:16 frcnn_kitti_darknet19.epoch1.tlt\n"
     ]
    }
   ],
   "source": [
    "# Copy weights to data directory.\n",
    "#!cp tlt_pretrained_object_detection_vresnet18/resnet_18.hdf5 $DATA_DOWNLOAD_DIR/faster_rcnn/\n",
    "!cp tlt_pretrained_object_detection_vdarknet19/darknet_19.hdf5 $DATA_DOWNLOAD_DIR/faster_rcnn/\n",
    "!rm -rf tlt_pretrained_object_detection_vdarknet19\n",
    "!ls -rlt $DATA_DOWNLOAD_DIR/faster_rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Provide training specification <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2017-2020, NVIDIA CORPORATION.  All rights reserved.\r\n",
      "random_seed: 42\r\n",
      "enc_key: 'tlt'\r\n",
      "verbose: True\r\n",
      "model_config {\r\n",
      "input_image_config {\r\n",
      "image_type: RGB\r\n",
      "image_channel_order: 'bgr'\r\n",
      "size_height_width {\r\n",
      "height: 384\r\n",
      "width: 1248\r\n",
      "}\r\n",
      "    image_channel_mean {\r\n",
      "        key: 'b'\r\n",
      "        value: 103.939\r\n",
      "}\r\n",
      "    image_channel_mean {\r\n",
      "        key: 'g'\r\n",
      "        value: 116.779\r\n",
      "}\r\n",
      "    image_channel_mean {\r\n",
      "        key: 'r'\r\n",
      "        value: 123.68\r\n",
      "}\r\n",
      "image_scaling_factor: 1.0\r\n",
      "max_objects_num_per_image: 100\r\n",
      "}\r\n",
      "arch: \"resnet:18\"\r\n",
      "anchor_box_config {\r\n",
      "scale: 64.0\r\n",
      "scale: 128.0\r\n",
      "scale: 256.0\r\n",
      "ratio: 1.0\r\n",
      "ratio: 0.5\r\n",
      "ratio: 2.0\r\n",
      "}\r\n",
      "freeze_bn: True\r\n",
      "freeze_blocks: 0\r\n",
      "freeze_blocks: 1\r\n",
      "roi_mini_batch: 256\r\n",
      "rpn_stride: 16\r\n",
      "use_bias: False\r\n",
      "roi_pooling_config {\r\n",
      "pool_size: 7\r\n",
      "pool_size_2x: False\r\n",
      "}\r\n",
      "all_projections: True\r\n",
      "use_pooling:False\r\n",
      "}\r\n",
      "dataset_config {\r\n",
      "  data_sources: {\r\n",
      "    tfrecords_path: \"/workspace/tlt-experiments/insect-thesis/kitti/noctuidae/tfrecords/kitti_trainval/kitti_trainval*\"\r\n",
      "    image_directory_path: \"/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/train\"\r\n",
      "  }\r\n",
      "image_extension: 'jpg'\r\n",
      "target_class_mapping {\r\n",
      "key: 'noctuidae'\r\n",
      "value: 'noctuidae'\r\n",
      "}\r\n",
      "\r\n",
      "validation_fold: 0\r\n",
      "}\r\n",
      "augmentation_config {\r\n",
      "preprocessing {\r\n",
      "output_image_width: 1248\r\n",
      "output_image_height: 384\r\n",
      "output_image_channel: 3\r\n",
      "min_bbox_width: 1.0\r\n",
      "min_bbox_height: 1.0\r\n",
      "}\r\n",
      "spatial_augmentation {\r\n",
      "hflip_probability: 0.5\r\n",
      "vflip_probability: 0.0\r\n",
      "zoom_min: 1.0\r\n",
      "zoom_max: 1.0\r\n",
      "translate_max_x: 0\r\n",
      "translate_max_y: 0\r\n",
      "}\r\n",
      "color_augmentation {\r\n",
      "hue_rotation_max: 0.0\r\n",
      "saturation_shift_max: 0.0\r\n",
      "contrast_scale_max: 0.0\r\n",
      "contrast_center: 0.5\r\n",
      "}\r\n",
      "}\r\n",
      "training_config {\r\n",
      "enable_augmentation: True\r\n",
      "enable_qat: False\r\n",
      "batch_size_per_gpu: 1\r\n",
      "num_epochs: 20\r\n",
      "pretrained_weights: \"/workspace/tlt-experiments/insect-thesis/data/faster_rcnn/resnet_18.hdf5\"\r\n",
      "#resume_from_model: \"/workspace/tlt-experiments/insect-thesis/data/faster_rcnn/resnet18.epoch2.tlt\"\r\n",
      "output_model: \"/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/frcnn_kitti_resnet18.tlt\"\r\n",
      "rpn_min_overlap: 0.3\r\n",
      "rpn_max_overlap: 0.7\r\n",
      "classifier_min_overlap: 0.0\r\n",
      "classifier_max_overlap: 0.5\r\n",
      "gt_as_roi: False\r\n",
      "std_scaling: 1.0\r\n",
      "classifier_regr_std {\r\n",
      "key: 'x'\r\n",
      "value: 10.0\r\n",
      "}\r\n",
      "classifier_regr_std {\r\n",
      "key: 'y'\r\n",
      "value: 10.0\r\n",
      "}\r\n",
      "classifier_regr_std {\r\n",
      "key: 'w'\r\n",
      "value: 5.0\r\n",
      "}\r\n",
      "classifier_regr_std {\r\n",
      "key: 'h'\r\n",
      "value: 5.0\r\n",
      "}\r\n",
      "\r\n",
      "rpn_mini_batch: 256\r\n",
      "rpn_pre_nms_top_N: 12000\r\n",
      "rpn_nms_max_boxes: 2000\r\n",
      "rpn_nms_overlap_threshold: 0.7\r\n",
      "\r\n",
      "regularizer {\r\n",
      "type: L2\r\n",
      "weight: 1e-4\r\n",
      "}\r\n",
      "\r\n",
      "optimizer {\r\n",
      "sgd {\r\n",
      "lr: 0.02\r\n",
      "momentum: 0.9\r\n",
      "decay: 0.0\r\n",
      "nesterov: False\r\n",
      "}\r\n",
      "}\r\n",
      "\r\n",
      "learning_rate {\r\n",
      "soft_start {\r\n",
      "base_lr: 0.02\r\n",
      "start_lr: 0.002\r\n",
      "soft_start: 0.1\r\n",
      "annealing_points: 0.8\r\n",
      "annealing_points: 0.9\r\n",
      "annealing_divider: 10.0\r\n",
      "}\r\n",
      "}\r\n",
      "\r\n",
      "lambda_rpn_regr: 1.0\r\n",
      "lambda_rpn_class: 1.0\r\n",
      "lambda_cls_regr: 1.0\r\n",
      "lambda_cls_class: 1.0\r\n",
      "}\r\n",
      "inference_config {\r\n",
      "images_dir: '/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/test/images'\r\n",
      "model: '/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/frcnn_kitti_resnet18.epoch20.tlt'\r\n",
      "batch_size: 1\r\n",
      "detection_image_output_dir: '/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/inference_results_imgs'\r\n",
      "labels_dump_dir: '/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/inference_dump_labels'\r\n",
      "rpn_pre_nms_top_N: 6000\r\n",
      "rpn_nms_max_boxes: 300\r\n",
      "rpn_nms_overlap_threshold: 0.7\r\n",
      "object_confidence_thres: 0.0001\r\n",
      "bbox_visualize_threshold: 0.6\r\n",
      "classifier_nms_max_boxes: 100\r\n",
      "classifier_nms_overlap_threshold: 0.3\r\n",
      "}\r\n",
      "evaluation_config {\r\n",
      "model: '/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/frcnn_kitti_resnet18.epoch20.tlt'\r\n",
      "batch_size: 1\r\n",
      "validation_period_during_training: 1\r\n",
      "labels_dump_dir: '/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/test_dump_labels'\r\n",
      "rpn_pre_nms_top_N: 6000\r\n",
      "rpn_nms_max_boxes: 300\r\n",
      "rpn_nms_overlap_threshold: 0.7\r\n",
      "classifier_nms_max_boxes: 100\r\n",
      "classifier_nms_overlap_threshold: 0.3\r\n",
      "object_confidence_thres: 0.0001\r\n",
      "use_voc07_11point_metric:False\r\n",
      "gt_matching_iou_threshold: 0.5\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!sed -i 's/$KEY/'\"$KEY/g\" $SPECS_DIR/default_spec_resnet18_custom.txt\n",
    "!cat $SPECS_DIR/default_spec_resnet18_custom.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Run TLT training <a class=\"anchor\" id=\"head-3\"></a>\n",
    " * Provide the sample spec file for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2021-03-22 15:58:35,262 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2021-03-22 15:58:35,262 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:47: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2021-03-22 15:58:35,301 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:47: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-03-22 15:58:35,301 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-03-22 15:58:35,570 [INFO] iva.faster_rcnn.spec_loader.spec_loader: Loading experiment spec at ./specs/default_spec_resnet18_custom.txt.\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-22 15:58:35,583 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-22 15:58:35,732 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-03-22 15:58:35,733 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-03-22 15:58:35,733 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-03-22 15:58:35,733 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 12, io threads: 24, compute threads: 12, buffered batches: 4\n",
      "2021-03-22 15:58:35,733 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 861, number of sources: 1, batch size per gpu: 1, steps: 861\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7ff4e62d6128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7ff4e62d6128>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 15:58:35,807 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7ff4e62d6128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7ff4e62d6128>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 15:58:35,824 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-03-22 15:58:36,049 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: True - shard 0 of 1\n",
      "2021-03-22 15:58:36,055 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-03-22 15:58:36,055 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7ff4d856c5f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7ff4d856c5f8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 15:58:36,067 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7ff4d856c5f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7ff4d856c5f8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/data_loader/inputs_loader.py:221: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "2021-03-22 15:58:36,562 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/data_loader/inputs_loader.py:221: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2021-03-22 15:58:36,575 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "2021-03-22 15:58:37,090 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "2021-03-22 15:58:37,272 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "2021-03-22 15:58:37,516 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "2021-03-22 15:58:37,565 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-03-22 15:58:37,705 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-03-22 15:58:37,734 [INFO] __main__: Loading pretrained weights from /workspace/tlt-experiments/insect-thesis/data/faster_rcnn/resnet_18.hdf5\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2021-03-22 15:58:37,735 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2021-03-22 15:58:37,735 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-03-22 15:58:37,951 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-03-22 15:58:38,283 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2021-03-22 15:58:38,306 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "===================================================================================================\n",
      "Pretrained weights loading status summary:\n",
      "None: layer has no weights at all.\n",
      "Yes: layer has weights and loaded successfully by name.\n",
      "No: layer has weights but names not match, skipped.\n",
      "===================================================================================================\n",
      "Layer(Type):                                                                              Status:  \n",
      "---------------------------------------------------------------------------------------------------\n",
      "input_image(InputLayer)                                                                   None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "conv1(Conv2D)                                                                             Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "bn_conv1(BatchNormalization)                                                              Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "activation_1(Activation)                                                                  None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_conv_1(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_relu_1(Activation)                                                               None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_conv_2(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_conv_shortcut(Conv2D)                                                            Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_1(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_relu(Activation)                                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_conv_1(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_relu_1(Activation)                                                               None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_conv_2(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_conv_shortcut(Conv2D)                                                            Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_2(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_relu(Activation)                                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_conv_1(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_relu_1(Activation)                                                               None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_conv_2(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_conv_shortcut(Conv2D)                                                            Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_3(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_relu(Activation)                                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_conv_1(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_relu_1(Activation)                                                               None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_conv_2(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_conv_shortcut(Conv2D)                                                            Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_4(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_relu(Activation)                                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_conv_1(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_relu_1(Activation)                                                               None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_conv_2(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_conv_shortcut(Conv2D)                                                            Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_5(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_relu(Activation)                                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_conv_1(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_relu_1(Activation)                                                               None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_conv_2(Conv2D)                                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_conv_shortcut(Conv2D)                                                            Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_6(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_relu(Activation)                                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "rpn_conv1(Conv2D)                                                                         No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "rpn_out_class(Conv2D)                                                                     No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "rpn_out_regress(Conv2D)                                                                   No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "proposal_1(Proposal)                                                                      None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "input_gt_cls(InputLayer)                                                                  None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "input_gt_bbox(InputLayer)                                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "proposal_target_1(ProposalTarget)                                                         None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "crop_and_resize_1(CropAndResize)                                                          None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_1(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_2(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4a_relu_1(Activation)                                                               None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_3(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_5(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_4(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_6(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_7(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4a_relu(Activation)                                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_7(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_8(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4b_relu_1(Activation)                                                               None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_9(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_11(TimeDistributed)                                                      Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_10(TimeDistributed)                                                      Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_12(TimeDistributed)                                                      Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_8(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4b_relu(Activation)                                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_13(TimeDistributed)                                                      None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_flatten(TimeDistributed)                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "dense_class_td(TimeDistributed)                                                           No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "dense_regress_td(TimeDistributed)                                                         No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2021-03-22 15:58:44,264 [INFO] __main__: Pretrained weights loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:64: The name tf.unsorted_segment_min is deprecated. Please use tf.math.unsorted_segment_min instead.\n",
      "\n",
      "2021-03-22 15:58:44,584 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:64: The name tf.unsorted_segment_min is deprecated. Please use tf.math.unsorted_segment_min instead.\n",
      "\n",
      "2021-03-22 15:58:45,390 [INFO] __main__: Building validation dataset...\n",
      "2021-03-22 15:58:45,906 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-03-22 15:58:45,906 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-03-22 15:58:45,906 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-03-22 15:58:45,906 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 12, io threads: 24, compute threads: 12, buffered batches: 4\n",
      "2021-03-22 15:58:45,906 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 140, number of sources: 1, batch size per gpu: 1, steps: 140\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7ff4885debe0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7ff4885debe0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 15:58:45,916 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7ff4885debe0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7ff4885debe0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 15:58:46,006 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-03-22 15:58:46,233 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2021-03-22 15:58:46,237 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-03-22 15:58:46,238 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7ff488470470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7ff488470470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 15:58:46,251 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7ff488470470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7ff488470470>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 15:58:46,650 [INFO] __main__: Validation dataset built successfully!\n",
      "2021-03-22 15:58:46,650 [INFO] iva.faster_rcnn.models.model_builder: Building validation model, may take a while...\n",
      "2021-03-22 16:00:10,052 [INFO] iva.faster_rcnn.models.model_builder: Validation model built successfully!\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-03-22 16:00:10,052 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 3, 384, 1248) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 192, 624) 9408        input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 192, 624) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 192, 624) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 96, 312)  36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 96, 312)  0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 96, 312)  36864       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 96, 312)  4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 96, 312)  0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 96, 312)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 96, 312)  36864       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 96, 312)  0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 96, 312)  36864       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 96, 312)  4096        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 96, 312)  0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 96, 312)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 48, 156) 73728       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 48, 156) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 48, 156) 147456      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 48, 156) 8192        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 48, 156) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 48, 156) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 48, 156) 147456      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 48, 156) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 48, 156) 147456      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 48, 156) 16384       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 48, 156) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 48, 156) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 24, 78)  294912      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 24, 78)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 24, 78)  589824      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 24, 78)  32768       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 24, 78)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 24, 78)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 24, 78)  589824      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 24, 78)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 24, 78)  589824      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 24, 78)  65536       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 24, 78)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 24, 78)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rpn_conv1 (Conv2D)              (None, 512, 24, 78)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_class (Conv2D)          (None, 9, 24, 78)    4617        rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_regress (Conv2D)        (None, 36, 24, 78)   18468       rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "proposal_1 (Proposal)           (None, 2000, 4)      0           rpn_out_class[0][0]              \n",
      "                                                                 rpn_out_regress[0][0]            \n",
      "                                                                 input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_cls (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_bbox (InputLayer)      (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "proposal_target_1 (ProposalTarg [(None, 256, 4), (No 0           proposal_1[0][0]                 \n",
      "                                                                 input_gt_cls[0][0]               \n",
      "                                                                 input_gt_bbox[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crop_and_resize_1 (CropAndResiz (None, 256, 256, 7,  0           block_3b_relu[0][0]              \n",
      "                                                                 proposal_target_1[0][0]          \n",
      "                                                                 input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 256, 512, 7,  1179648     crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 256, 512, 7,  0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 256, 512, 7,  2359296     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 256, 512, 7,  131072      crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 256, 512, 7,  0           time_distributed_4[0][0]         \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 256, 512, 7,  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 256, 512, 7,  2359296     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 256, 512, 7,  0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 256, 512, 7,  2359296     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 256, 512, 7,  262144      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 256, 512, 7,  2048        time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 256, 512, 7,  2048        time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 256, 512, 7,  0           time_distributed_10[0][0]        \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 256, 512, 7,  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 256, 512, 1,  0           block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_flatten (TimeD (None, 256, 512)     0           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_class_td (TimeDistributed (None, 256, 2)       1026        time_distributed_flatten[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_regress_td (TimeDistribut (None, 256, 4)       2052        time_distributed_flatten[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 12,748,787\n",
      "Trainable params: 12,572,083\n",
      "Non-trainable params: 176,704\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:22: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "2021-03-22 16:00:10,179 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:22: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:23: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "2021-03-22 16:00:10,180 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:23: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:24: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "2021-03-22 16:00:10,180 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:24: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "2021-03-22 16:00:11,866 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "2021-03-22 16:00:12,010 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/20\n",
      "  2/861 [..............................] - ETA: 1:00:55 - loss: 2.1747 - rpn_out_class_loss: 0.6701 - rpn_out_regress_loss: 0.0286 - dense_class_td_loss: 0.9335 - dense_regress_td_loss: 0.0819 - dense_class_td_acc: 0.7148/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.857063). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "861/861 [==============================] - 82s 95ms/step - loss: 0.8283 - rpn_out_class_loss: 0.0332 - rpn_out_regress_loss: 0.0145 - dense_class_td_loss: 0.1473 - dense_regress_td_loss: 0.1753 - dense_class_td_acc: 0.9378\n",
      "1a99031ed061:690:718 [0] NCCL INFO Bootstrap : Using [0]lo:127.0.0.1<0> [1]eth0:172.17.0.2<0>\n",
      "1a99031ed061:690:718 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
      "1a99031ed061:690:718 [0] NCCL INFO NET/IB : No device found.\n",
      "1a99031ed061:690:718 [0] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0> [1]eth0:172.17.0.2<0>\n",
      "1a99031ed061:690:718 [0] NCCL INFO Using network Socket\n",
      "NCCL version 2.7.8+cuda11.1\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 00/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 01/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 02/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 03/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 04/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 05/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 06/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 07/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 08/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 09/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 10/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 11/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 12/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 13/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 14/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 15/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 16/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 17/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 18/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 19/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 20/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 21/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 22/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 23/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 24/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 25/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 26/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 27/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 28/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 29/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 30/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Channel 31/32 :    0\n",
      "1a99031ed061:690:718 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [1] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [2] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [3] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [4] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [5] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [6] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [7] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [8] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [9] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [10] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [11] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [12] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [13] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [14] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [15] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [16] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [17] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [18] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [19] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [20] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [21] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [22] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [23] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [24] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [25] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [26] -1/-1/-1->0->-1|-1->0->-1\n",
      "1a99031ed061:690:718 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "1a99031ed061:690:718 [0] NCCL INFO comm 0x7ff4dc32a160 rank 0 nranks 1 cudaDev 0 busId 1000 - Init COMPLETE\n",
      "Doing validation at epoch 1(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:06<00:00, 21.35it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.6656              0.0288              0.8417              0.9784              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.6656              \n",
      "Validation done!\n",
      "Epoch 2/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.7011 - rpn_out_class_loss: 0.0219 - rpn_out_regress_loss: 0.0119 - dense_class_td_loss: 0.1004 - dense_regress_td_loss: 0.1205 - dense_class_td_acc: 0.9557\n",
      "Doing validation at epoch 2(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.41it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.8452              0.0413              0.9137              0.9856              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.8452              \n",
      "Validation done!\n",
      "Epoch 3/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.6241 - rpn_out_class_loss: 0.0197 - rpn_out_regress_loss: 0.0074 - dense_class_td_loss: 0.0767 - dense_regress_td_loss: 0.0943 - dense_class_td_acc: 0.9655\n",
      "Doing validation at epoch 3(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.46it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9000              0.0279              0.9496              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9000              \n",
      "Validation done!\n",
      "Epoch 4/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.5651 - rpn_out_class_loss: 0.0177 - rpn_out_regress_loss: 0.0055 - dense_class_td_loss: 0.0634 - dense_regress_td_loss: 0.0747 - dense_class_td_acc: 0.9716\n",
      "Doing validation at epoch 4(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.52it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9153              0.0546              0.9568              0.9496              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9153              \n",
      "Validation done!\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861/861 [==============================] - 74s 86ms/step - loss: 0.5230 - rpn_out_class_loss: 0.0159 - rpn_out_regress_loss: 0.0046 - dense_class_td_loss: 0.0541 - dense_regress_td_loss: 0.0658 - dense_class_td_acc: 0.9752\n",
      "Doing validation at epoch 5(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.40it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9172              0.0595              0.9496              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9172              \n",
      "Validation done!\n",
      "Epoch 6/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.4953 - rpn_out_class_loss: 0.0165 - rpn_out_regress_loss: 0.0045 - dense_class_td_loss: 0.0505 - dense_regress_td_loss: 0.0608 - dense_class_td_acc: 0.9769\n",
      "Doing validation at epoch 6(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.57it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9498              0.0720              0.9712              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9498              \n",
      "Validation done!\n",
      "Epoch 7/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.4636 - rpn_out_class_loss: 0.0147 - rpn_out_regress_loss: 0.0041 - dense_class_td_loss: 0.0462 - dense_regress_td_loss: 0.0541 - dense_class_td_acc: 0.9787\n",
      "Doing validation at epoch 7(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.43it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9473              0.0397              0.9640              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9473              \n",
      "Validation done!\n",
      "Epoch 8/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.4433 - rpn_out_class_loss: 0.0147 - rpn_out_regress_loss: 0.0039 - dense_class_td_loss: 0.0453 - dense_regress_td_loss: 0.0524 - dense_class_td_acc: 0.9792\n",
      "Doing validation at epoch 8(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.47it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9246              0.0912              0.9568              0.9784              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9246              \n",
      "Validation done!\n",
      "Epoch 9/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.4165 - rpn_out_class_loss: 0.0137 - rpn_out_regress_loss: 0.0041 - dense_class_td_loss: 0.0396 - dense_regress_td_loss: 0.0484 - dense_class_td_acc: 0.9813\n",
      "Doing validation at epoch 9(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.29it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9515              0.0579              0.9640              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9515              \n",
      "Validation done!\n",
      "Epoch 10/20\n",
      "861/861 [==============================] - 75s 87ms/step - loss: 0.4036 - rpn_out_class_loss: 0.0132 - rpn_out_regress_loss: 0.0038 - dense_class_td_loss: 0.0415 - dense_regress_td_loss: 0.0496 - dense_class_td_acc: 0.9807\n",
      "Doing validation at epoch 10(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.38it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9539              0.0998              0.9640              0.9496              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9539              \n",
      "Validation done!\n",
      "Epoch 11/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.3821 - rpn_out_class_loss: 0.0128 - rpn_out_regress_loss: 0.0037 - dense_class_td_loss: 0.0396 - dense_regress_td_loss: 0.0446 - dense_class_td_acc: 0.9818\n",
      "Doing validation at epoch 11(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.28it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9670              0.0806              0.9856              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9670              \n",
      "Validation done!\n",
      "Epoch 12/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.3635 - rpn_out_class_loss: 0.0116 - rpn_out_regress_loss: 0.0035 - dense_class_td_loss: 0.0381 - dense_regress_td_loss: 0.0423 - dense_class_td_acc: 0.9820\n",
      "Doing validation at epoch 12(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.35it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9653              0.1373              0.9856              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9653              \n",
      "Validation done!\n",
      "Epoch 13/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.3534 - rpn_out_class_loss: 0.0126 - rpn_out_regress_loss: 0.0035 - dense_class_td_loss: 0.0383 - dense_regress_td_loss: 0.0437 - dense_class_td_acc: 0.9821\n",
      "Doing validation at epoch 13(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.28it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9694              0.0497              0.9856              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9694              \n",
      "Validation done!\n",
      "Epoch 14/20\n",
      "861/861 [==============================] - 75s 87ms/step - loss: 0.3363 - rpn_out_class_loss: 0.0114 - rpn_out_regress_loss: 0.0035 - dense_class_td_loss: 0.0354 - dense_regress_td_loss: 0.0418 - dense_class_td_acc: 0.9832\n",
      "Doing validation at epoch 14(1-based index)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 25.72it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9464              0.0557              0.9640              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9464              \n",
      "Validation done!\n",
      "Epoch 15/20\n",
      "861/861 [==============================] - 77s 89ms/step - loss: 0.3252 - rpn_out_class_loss: 0.0117 - rpn_out_regress_loss: 0.0034 - dense_class_td_loss: 0.0353 - dense_regress_td_loss: 0.0413 - dense_class_td_acc: 0.9834\n",
      "Doing validation at epoch 15(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 26.05it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9841              0.1214              0.9928              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9841              \n",
      "Validation done!\n",
      "Epoch 16/20\n",
      "861/861 [==============================] - 75s 87ms/step - loss: 0.3029 - rpn_out_class_loss: 0.0105 - rpn_out_regress_loss: 0.0032 - dense_class_td_loss: 0.0315 - dense_regress_td_loss: 0.0344 - dense_class_td_acc: 0.9848\n",
      "Doing validation at epoch 16(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.40it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9418              0.1238              0.9640              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9418              \n",
      "Validation done!\n",
      "Epoch 17/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.2822 - rpn_out_class_loss: 0.0090 - rpn_out_regress_loss: 0.0021 - dense_class_td_loss: 0.0259 - dense_regress_td_loss: 0.0276 - dense_class_td_acc: 0.9871\n",
      "Doing validation at epoch 17(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.23it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9919              0.1518              0.9928              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9919              \n",
      "Validation done!\n",
      "Epoch 18/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.2756 - rpn_out_class_loss: 0.0082 - rpn_out_regress_loss: 0.0018 - dense_class_td_loss: 0.0246 - dense_regress_td_loss: 0.0246 - dense_class_td_acc: 0.9878\n",
      "Doing validation at epoch 18(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.17it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9910              0.1260              0.9928              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9910              \n",
      "Validation done!\n",
      "Epoch 19/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.2706 - rpn_out_class_loss: 0.0077 - rpn_out_regress_loss: 0.0017 - dense_class_td_loss: 0.0231 - dense_regress_td_loss: 0.0224 - dense_class_td_acc: 0.9885\n",
      "Doing validation at epoch 19(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.23it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9830              0.1341              0.9856              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9830              \n",
      "Validation done!\n",
      "Epoch 20/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.2717 - rpn_out_class_loss: 0.0079 - rpn_out_regress_loss: 0.0017 - dense_class_td_loss: 0.0235 - dense_regress_td_loss: 0.0230 - dense_class_td_acc: 0.9884\n",
      "Doing validation at epoch 20(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 27.17it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9846              0.1341              0.9928              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9846              \n",
      "Validation done!\n"
     ]
    }
   ],
   "source": [
    "!faster_rcnn train --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_custom.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for each epoch:\n",
      "---------------------\n",
      "total 242M\r\n",
      "-rw------- 1 root root 153M Mar 21 13:58 darknet_19.hdf5\r\n",
      "-rwxrwxrwx 1 root root  89M Mar 20 13:11 resnet_18.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "print('Model for each epoch:')\n",
    "print('---------------------')\n",
    "!ls -lht $USER_EXPERIMENT_DIR/data/faster_rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For multi-GPU, please uncomment and run this instead. Change --gpus  and --gpu_index based on your machine.\")\n",
    "# !faster_rcnn train -e $SPECS_DIR/default_spec_resnet18.txt \\\n",
    "#                    --gpus 2 \\\n",
    "#                    --gpu_index 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For resume training from checkpoint, please uncomment and run this instead. Change/Add the 'resume_from_model' field in the spec file.\")\n",
    "# !faster_rcnn train --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For Automatic Mixed Precision(AMP) training, please uncomment and run this. Make sure you use the Volta or above GPU arch to enable AMP.\")\n",
    "# !faster_rcnn train --gpu_index $GPU_INDEX --use_amp -e $SPECS_DIR/default_spec_resnet18.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4. Evaluate trained models <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "2021-03-22 16:32:20,669 [INFO] iva.faster_rcnn.spec_loader.spec_loader: Loading experiment spec at ./specs/default_spec_resnet18_custom.txt.\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/evaluate.py:60: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2021-03-22 16:32:20,682 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/evaluate.py:60: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/evaluate.py:62: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-03-22 16:32:20,682 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/evaluate.py:62: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2021-03-22 16:32:21,161 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-22 16:32:21,161 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-22 16:32:21,161 [INFO] __main__: Running evaluation with TLT as backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-03-22 16:32:21,932 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2021-03-22 16:32:21,944 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "2021-03-22 16:32:22,421 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:77: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "2021-03-22 16:32:22,424 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:77: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "2021-03-22 16:32:22,606 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "2021-03-22 16:32:22,856 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "2021-03-22 16:32:22,908 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-03-22 16:32:23,046 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2021-03-22 16:32:23,306 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2021-03-22 16:32:23,306 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2021-03-22 16:32:23,306 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-03-22 16:32:23,484 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-03-22 16:32:23,806 [INFO] __main__: Building evaluation model, may take a while...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "2021-03-22 16:32:48,941 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2021-03-22 16:32:48,988 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 3, 384, 1248) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 192, 624) 9408        input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 192, 624) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 192, 624) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 96, 312)  36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 96, 312)  0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 96, 312)  36864       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 96, 312)  4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 96, 312)  0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 96, 312)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 96, 312)  36864       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 96, 312)  0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 96, 312)  36864       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 96, 312)  4096        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 96, 312)  0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 96, 312)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 48, 156) 73728       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 48, 156) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 48, 156) 147456      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 48, 156) 8192        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 48, 156) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 48, 156) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 48, 156) 147456      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 48, 156) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 48, 156) 147456      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 48, 156) 16384       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 48, 156) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 48, 156) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 24, 78)  294912      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 24, 78)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 24, 78)  589824      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 24, 78)  32768       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 24, 78)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 24, 78)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 24, 78)  589824      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 24, 78)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 24, 78)  589824      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 24, 78)  65536       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 24, 78)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 24, 78)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rpn_conv1 (Conv2D)              (None, 512, 24, 78)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_class (Conv2D)          (None, 9, 24, 78)    4617        rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_regress (Conv2D)        (None, 36, 24, 78)   18468       rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "proposal_1 (Proposal)           (None, 300, 4)       0           rpn_out_class[0][0]              \n",
      "                                                                 rpn_out_regress[0][0]            \n",
      "                                                                 input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "crop_and_resize_1 (CropAndResiz (None, 300, 256, 7,  0           block_3b_relu[0][0]              \n",
      "                                                                 proposal_1[0][0]                 \n",
      "                                                                 input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 300, 512, 7,  1179648     crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 300, 512, 7,  0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 300, 512, 7,  2359296     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 300, 512, 7,  131072      crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 300, 512, 7,  0           time_distributed_4[0][0]         \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 300, 512, 7,  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 300, 512, 7,  2359296     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 300, 512, 7,  0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 300, 512, 7,  2359296     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 300, 512, 7,  262144      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 300, 512, 7,  2048        time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 300, 512, 7,  2048        time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 300, 512, 7,  0           time_distributed_10[0][0]        \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 300, 512, 7,  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 300, 512, 1,  0           block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_flatten (TimeD (None, 300, 512)     0           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_class_td (TimeDistributed (None, 300, 2)       1026        time_distributed_flatten[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_regress_td (TimeDistribut (None, 300, 4)       2052        time_distributed_flatten[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "output_parser_1 (OutputParser)  [(None, 100, 4), (No 0           proposal_1[0][0]                 \n",
      "                                                                 dense_class_td[0][0]             \n",
      "                                                                 dense_regress_td[0][0]           \n",
      "                                                                 input_image[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 12,748,787\n",
      "Trainable params: 12,572,083\n",
      "Non-trainable params: 176,704\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-22 16:32:50,595 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-03-22 16:32:50,595 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-03-22 16:32:50,595 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-03-22 16:32:50,595 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 12, io threads: 24, compute threads: 12, buffered batches: 4\n",
      "2021-03-22 16:32:50,595 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 140, number of sources: 1, batch size per gpu: 1, steps: 140\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f048c4fb080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f048c4fb080>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 16:32:50,660 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f048c4fb080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f048c4fb080>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 16:32:50,676 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-03-22 16:32:50,907 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2021-03-22 16:32:50,911 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-03-22 16:32:50,911 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f043450bda0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f043450bda0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 16:32:50,925 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f043450bda0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f043450bda0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:22: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "2021-03-22 16:32:51,347 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:22: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:23: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "2021-03-22 16:32:51,348 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:23: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:24: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "2021-03-22 16:32:51,348 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:24: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "100%|█████████████████████████████████████████| 140/140 [00:08<00:00, 16.27it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9907              0.1316              0.9928              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9907              \n"
     ]
    }
   ],
   "source": [
    "!faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_custom.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Prune trained models <a class=\"anchor\" id=\"head-5\"></a>\n",
    " * Specify pre-trained model\n",
    " * Equalization criterion\n",
    " * Threshold for pruning\n",
    " * A key to save and load the model\n",
    " * Output directory to store the model\n",
    " \n",
    "Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold to use is depend on the dataset. A `pth` value below is just a start point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "2021-03-22 16:34:19,324 [INFO] modulus.pruning.pruning: Exploring graph for retainable indices\n",
      "2021-03-22 16:34:20,461 [INFO] modulus.pruning.pruning: Pruning model and appending pruned nodes to new graph\n",
      "2021-03-22 16:34:48,081 [INFO] iva.common.magnet_prune: Pruning ratio (pruned model / original model): 0.9990072781041835\n"
     ]
    }
   ],
   "source": [
    "!faster_rcnn prune --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/data/kitti/noctuidae/faster_rcnn/frcnn_kitti_resnet18.epoch20.tlt \\\n",
    "           -o $USER_EXPERIMENT_DIR/data/kitti/noctuidae/faster_rcnn/model_1_pruned.tlt  \\\n",
    "           -eq union  \\\n",
    "           -pth 0.2 \\\n",
    "           -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.0G\r\n",
      "-rw-r--r-- 1 root root 49M Mar 22 16:34 model_1_pruned.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:27 frcnn_kitti_resnet18.epoch20.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:26 frcnn_kitti_resnet18.epoch19.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:24 frcnn_kitti_resnet18.epoch18.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:23 frcnn_kitti_resnet18.epoch17.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:22 frcnn_kitti_resnet18.epoch16.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:20 frcnn_kitti_resnet18.epoch15.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:19 frcnn_kitti_resnet18.epoch14.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:18 frcnn_kitti_resnet18.epoch13.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:16 frcnn_kitti_resnet18.epoch12.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:15 frcnn_kitti_resnet18.epoch11.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:14 frcnn_kitti_resnet18.epoch10.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:12 frcnn_kitti_resnet18.epoch9.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:11 frcnn_kitti_resnet18.epoch8.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:10 frcnn_kitti_resnet18.epoch7.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:08 frcnn_kitti_resnet18.epoch6.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:07 frcnn_kitti_resnet18.epoch5.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:06 frcnn_kitti_resnet18.epoch4.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:04 frcnn_kitti_resnet18.epoch3.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:03 frcnn_kitti_resnet18.epoch2.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:02 frcnn_kitti_resnet18.epoch1.tlt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lht $USER_EXPERIMENT_DIR/data/kitti/noctuidae/faster_rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Retrain pruned models <a class=\"anchor\" id=\"head-6\"></a>\n",
    " * Model needs to be re-trained to bring back accuracy after pruning\n",
    " * Specify re-training specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2017-2020, NVIDIA CORPORATION.  All rights reserved.\r\n",
      "random_seed: 42\r\n",
      "enc_key: 'tlt'\r\n",
      "verbose: True\r\n",
      "model_config {\r\n",
      "input_image_config {\r\n",
      "image_type: RGB\r\n",
      "image_channel_order: 'bgr'\r\n",
      "size_height_width {\r\n",
      "height: 384\r\n",
      "width: 1248\r\n",
      "}\r\n",
      "    image_channel_mean {\r\n",
      "        key: 'b'\r\n",
      "        value: 103.939\r\n",
      "}\r\n",
      "    image_channel_mean {\r\n",
      "        key: 'g'\r\n",
      "        value: 116.779\r\n",
      "}\r\n",
      "    image_channel_mean {\r\n",
      "        key: 'r'\r\n",
      "        value: 123.68\r\n",
      "}\r\n",
      "image_scaling_factor: 1.0\r\n",
      "max_objects_num_per_image: 100\r\n",
      "}\r\n",
      "arch: \"resnet:18\"\r\n",
      "anchor_box_config {\r\n",
      "scale: 64.0\r\n",
      "scale: 128.0\r\n",
      "scale: 256.0\r\n",
      "ratio: 1.0\r\n",
      "ratio: 0.5\r\n",
      "ratio: 2.0\r\n",
      "}\r\n",
      "freeze_bn: True\r\n",
      "freeze_blocks: 0\r\n",
      "freeze_blocks: 1\r\n",
      "roi_mini_batch: 256\r\n",
      "rpn_stride: 16\r\n",
      "use_bias: False\r\n",
      "roi_pooling_config {\r\n",
      "pool_size: 7\r\n",
      "pool_size_2x: False\r\n",
      "}\r\n",
      "all_projections: True\r\n",
      "use_pooling:False\r\n",
      "}\r\n",
      "dataset_config {\r\n",
      "  data_sources: {\r\n",
      "    tfrecords_path: \"/workspace/tlt-experiments/data/kitti/noctuidae/tfrecords/kitti_trainval/kitti_trainval*\"\r\n",
      "    image_directory_path: \"/workspace/tlt-experiments/data/kitti/noctuidae/train\"\r\n",
      "  }\r\n",
      "image_extension: 'jpg'\r\n",
      "target_class_mapping {\r\n",
      "key: 'noctuidae'\r\n",
      "value: 'noctuidae'\r\n",
      "}\r\n",
      "\r\n",
      "validation_fold: 0\r\n",
      "}\r\n",
      "augmentation_config {\r\n",
      "preprocessing {\r\n",
      "output_image_width: 1248\r\n",
      "output_image_height: 384\r\n",
      "output_image_channel: 3\r\n",
      "min_bbox_width: 1.0\r\n",
      "min_bbox_height: 1.0\r\n",
      "}\r\n",
      "spatial_augmentation {\r\n",
      "hflip_probability: 0.5\r\n",
      "vflip_probability: 0.0\r\n",
      "zoom_min: 1.0\r\n",
      "zoom_max: 1.0\r\n",
      "translate_max_x: 0\r\n",
      "translate_max_y: 0\r\n",
      "}\r\n",
      "color_augmentation {\r\n",
      "hue_rotation_max: 0.0\r\n",
      "saturation_shift_max: 0.0\r\n",
      "contrast_scale_max: 0.0\r\n",
      "contrast_center: 0.5\r\n",
      "}\r\n",
      "}\r\n",
      "training_config {\r\n",
      "enable_augmentation: True\r\n",
      "enable_qat: True\r\n",
      "batch_size_per_gpu: 1\r\n",
      "num_epochs: 12\r\n",
      "retrain_pruned_model: \"/workspace/tlt-experiments/data/kitti/noctuidae/faster_rcnn/model_1_pruned.tlt\"\r\n",
      "output_model: \"/workspace/tlt-experiments/data/kitti/noctuidae/faster_rcnn/frcnn_kitti_resnet18_retrain.tlt\"\r\n",
      "rpn_min_overlap: 0.3\r\n",
      "rpn_max_overlap: 0.7\r\n",
      "classifier_min_overlap: 0.0\r\n",
      "classifier_max_overlap: 0.5\r\n",
      "gt_as_roi: False\r\n",
      "std_scaling: 1.0\r\n",
      "classifier_regr_std {\r\n",
      "key: 'x'\r\n",
      "value: 10.0\r\n",
      "}\r\n",
      "classifier_regr_std {\r\n",
      "key: 'y'\r\n",
      "value: 10.0\r\n",
      "}\r\n",
      "classifier_regr_std {\r\n",
      "key: 'w'\r\n",
      "value: 5.0\r\n",
      "}\r\n",
      "classifier_regr_std {\r\n",
      "key: 'h'\r\n",
      "value: 5.0\r\n",
      "}\r\n",
      "\r\n",
      "rpn_mini_batch: 256\r\n",
      "rpn_pre_nms_top_N: 12000\r\n",
      "rpn_nms_max_boxes: 2000\r\n",
      "rpn_nms_overlap_threshold: 0.7\r\n",
      "\r\n",
      "regularizer {\r\n",
      "type: L2\r\n",
      "weight: 1e-4\r\n",
      "}\r\n",
      "\r\n",
      "optimizer {\r\n",
      "sgd {\r\n",
      "lr: 0.02\r\n",
      "momentum: 0.9\r\n",
      "decay: 0.0\r\n",
      "nesterov: False\r\n",
      "}\r\n",
      "}\r\n",
      "\r\n",
      "learning_rate {\r\n",
      "soft_start {\r\n",
      "base_lr: 0.02\r\n",
      "start_lr: 0.002\r\n",
      "soft_start: 0.1\r\n",
      "annealing_points: 0.8\r\n",
      "annealing_points: 0.9\r\n",
      "annealing_divider: 10.0\r\n",
      "}\r\n",
      "}\r\n",
      "\r\n",
      "lambda_rpn_regr: 1.0\r\n",
      "lambda_rpn_class: 1.0\r\n",
      "lambda_cls_regr: 1.0\r\n",
      "lambda_cls_class: 1.0\r\n",
      "}\r\n",
      "inference_config {\r\n",
      "images_dir: '/workspace/tlt-experiments/data/kitti/noctuidae/test/images'\r\n",
      "model: '/workspace/tlt-experiments/data/kitti/noctuidae/faster_rcnn/frcnn_kitti_resnet18_retrain.epoch20.tlt'\r\n",
      "batch_size: 1\r\n",
      "detection_image_output_dir: '/workspace/tlt-experiments/data/kitti/noctuidae/faster_rcnn/inference_results_imgs_retrain'\r\n",
      "labels_dump_dir: '/workspace/tlt-experiments/data/kitti/noctuidae/faster_rcnn/inference_dump_labels_retrain'\r\n",
      "rpn_pre_nms_top_N: 6000\r\n",
      "rpn_nms_max_boxes: 300\r\n",
      "rpn_nms_overlap_threshold: 0.7\r\n",
      "object_confidence_thres: 0.0001\r\n",
      "bbox_visualize_threshold: 0.6\r\n",
      "classifier_nms_max_boxes: 100\r\n",
      "classifier_nms_overlap_threshold: 0.3\r\n",
      "#trt_inference {\r\n",
      "#trt_engine: '/workspace/tlt-experiments/data/kitti/noctuidae/faster_rcnn/trt.int8.engine'\r\n",
      "#trt_data_type: 'int8'\r\n",
      "#max_workspace_size_MB: 2000\r\n",
      "#}\r\n",
      "}\r\n",
      "evaluation_config {\r\n",
      "model: '/workspace/tlt-experiments/data/kitti/noctuidae/faster_rcnn/frcnn_kitti_resnet18_retrain.epoch20.tlt'\r\n",
      "batch_size: 1\r\n",
      "validation_period_during_training: 1\r\n",
      "labels_dump_dir: '/workspace/tlt-experiments/data/kitti/noctuidae/faster_rcnn/test_dump_labels_retrain'\r\n",
      "rpn_pre_nms_top_N: 6000\r\n",
      "rpn_nms_max_boxes: 300\r\n",
      "rpn_nms_overlap_threshold: 0.7\r\n",
      "classifier_nms_max_boxes: 100\r\n",
      "classifier_nms_overlap_threshold: 0.3\r\n",
      "object_confidence_thres: 0.0001\r\n",
      "use_voc07_11point_metric:False\r\n",
      "#trt_evaluation {\r\n",
      "#trt_engine: '/workspace/tlt-experiments/data/kitti/noctuidae/faster_rcnn/trt.int8.engine'\r\n",
      "#trt_data_type: 'int8'\r\n",
      "#max_workspace_size_MB: 2000\r\n",
      "#}\r\n",
      "gt_matching_iou_threshold: 0.5\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# Here we have updated the spec file to include the newly pruned model as a pretrained weights.\n",
    "!sed -i 's/$KEY/'\"$KEY/g\" $SPECS_DIR/default_spec_resnet18_retrain_spec_custom.txt\n",
    "!cat $SPECS_DIR/default_spec_resnet18_retrain_spec_custom.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2021-03-22 16:50:59,684 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2021-03-22 16:50:59,684 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:47: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2021-03-22 16:50:59,732 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:47: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-03-22 16:50:59,732 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-03-22 16:50:59,992 [INFO] iva.faster_rcnn.spec_loader.spec_loader: Loading experiment spec at ./specs/default_spec_resnet18_retrain_spec_custom.txt.\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-22 16:51:00,005 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-22 16:51:00,140 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-03-22 16:51:00,140 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-03-22 16:51:00,141 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-03-22 16:51:00,141 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 12, io threads: 24, compute threads: 12, buffered batches: 4\n",
      "2021-03-22 16:51:00,141 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 861, number of sources: 1, batch size per gpu: 1, steps: 861\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f2da4413128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f2da4413128>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 16:51:00,215 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f2da4413128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f2da4413128>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 16:51:00,231 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-03-22 16:51:00,458 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: True - shard 0 of 1\n",
      "2021-03-22 16:51:00,463 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-03-22 16:51:00,463 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f2d8e6d35f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f2d8e6d35f8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 16:51:00,476 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f2d8e6d35f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f2d8e6d35f8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/data_loader/inputs_loader.py:221: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "2021-03-22 16:51:00,977 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/data_loader/inputs_loader.py:221: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "2021-03-22 16:51:00,989 [INFO] __main__: Loading pretrained model: /workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/model_1_pruned.tlt for retrain.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-03-22 16:51:01,396 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2021-03-22 16:51:01,407 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2021-03-22 16:51:01,421 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "2021-03-22 16:51:01,890 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "2021-03-22 16:51:02,083 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "2021-03-22 16:51:02,331 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "2021-03-22 16:51:02,383 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-03-22 16:51:02,521 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2021-03-22 16:51:02,715 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2021-03-22 16:51:02,715 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-03-22 16:51:02,930 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-03-22 16:51:03,299 [INFO] __main__: Pruned model loaded!\n",
      "2021-03-22 16:51:07,626 [INFO] __main__: Regularizers updated for the loaded model.\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:64: The name tf.unsorted_segment_min is deprecated. Please use tf.math.unsorted_segment_min instead.\n",
      "\n",
      "2021-03-22 16:52:19,522 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:64: The name tf.unsorted_segment_min is deprecated. Please use tf.math.unsorted_segment_min instead.\n",
      "\n",
      "2021-03-22 16:52:21,013 [INFO] __main__: Building validation dataset...\n",
      "2021-03-22 16:52:21,988 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-03-22 16:52:21,988 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-03-22 16:52:21,988 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-03-22 16:52:21,988 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 12, io threads: 24, compute threads: 12, buffered batches: 4\n",
      "2021-03-22 16:52:21,988 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 140, number of sources: 1, batch size per gpu: 1, steps: 140\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f2c9d4c62b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f2c9d4c62b0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 16:52:21,997 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f2c9d4c62b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f2c9d4c62b0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 16:52:22,013 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-22 16:52:22,236 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2021-03-22 16:52:22,241 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-03-22 16:52:22,241 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f2c9d3657b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f2c9d3657b8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 16:52:22,253 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f2c9d3657b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f2c9d3657b8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 16:52:22,638 [INFO] __main__: Validation dataset built successfully!\n",
      "2021-03-22 16:52:22,638 [INFO] iva.faster_rcnn.models.model_builder: Building validation model, may take a while...\n",
      "2021-03-22 16:54:25,542 [INFO] iva.faster_rcnn.models.model_builder: Validation model built successfully!\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-03-22 16:54:25,542 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 3, 384, 1248) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 192, 624) 7056        input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 48, 192, 624) 192         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 192, 624) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 96, 312)  27648       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 96, 312)  0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 96, 312)  36864       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 96, 312)  3072        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 96, 312)  0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 96, 312)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 96, 312)  36864       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 96, 312)  0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 96, 312)  36864       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 96, 312)  4096        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 96, 312)  0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 96, 312)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 48, 156) 73728       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 48, 156) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 48, 156) 147456      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 48, 156) 8192        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 48, 156) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 48, 156) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 48, 156) 147456      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 48, 156) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 48, 156) 147456      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 48, 156) 16384       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 48, 156) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 48, 156) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 24, 78)  294912      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 24, 78)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 24, 78)  589824      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 24, 78)  32768       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 24, 78)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 24, 78)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 24, 78)  589824      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 24, 78)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 24, 78)  589824      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 24, 78)  65536       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 24, 78)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 24, 78)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rpn_conv1 (Conv2D)              (None, 512, 24, 78)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_class (Conv2D)          (None, 9, 24, 78)    4617        rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_regress (Conv2D)        (None, 36, 24, 78)   18468       rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "proposal_1 (Proposal)           (None, 2000, 4)      0           rpn_out_class[0][0]              \n",
      "                                                                 rpn_out_regress[0][0]            \n",
      "                                                                 input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_cls (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_bbox (InputLayer)      (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "proposal_target_1 (ProposalTarg [(None, 256, 4), (No 0           proposal_1[0][0]                 \n",
      "                                                                 input_gt_cls[0][0]               \n",
      "                                                                 input_gt_bbox[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crop_and_resize_1 (CropAndResiz (None, 256, 256, 7,  0           block_3b_relu[0][0]              \n",
      "                                                                 proposal_target_1[0][0]          \n",
      "                                                                 input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 256, 512, 7,  1179648     crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 256, 512, 7,  0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 256, 512, 7,  2359296     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 256, 512, 7,  131072      crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 256, 512, 7,  0           time_distributed_4[0][0]         \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 256, 512, 7,  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 256, 512, 7,  2359296     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 256, 512, 7,  0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 256, 512, 7,  2359296     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 256, 512, 7,  262144      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 256, 512, 7,  2048        time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 256, 512, 7,  2048        time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 256, 512, 7,  0           time_distributed_10[0][0]        \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 256, 512, 7,  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 256, 512, 1,  0           block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_flatten (TimeD (None, 256, 512)     0           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_class_td (TimeDistributed (None, 256, 2)       1026        time_distributed_flatten[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_regress_td (TimeDistribut (None, 256, 4)       2052        time_distributed_flatten[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 12,736,131\n",
      "Trainable params: 12,572,051\n",
      "Non-trainable params: 164,080\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:22: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "2021-03-22 16:54:25,659 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:22: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:23: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "2021-03-22 16:54:25,659 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:23: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:24: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "2021-03-22 16:54:25,660 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:24: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "2021-03-22 16:54:27,409 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "2021-03-22 16:54:27,543 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/20\n",
      "  2/861 [..............................] - ETA: 1:01:45 - loss: 0.2483 - rpn_out_class_loss: 0.0012 - rpn_out_regress_loss: 0.0018 - dense_class_td_loss: 0.0229 - dense_regress_td_loss: 0.0073 - dense_class_td_acc: 0.9922/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (1.151097). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "861/861 [==============================] - 80s 93ms/step - loss: 0.2682 - rpn_out_class_loss: 0.0082 - rpn_out_regress_loss: 0.0019 - dense_class_td_loss: 0.0221 - dense_regress_td_loss: 0.0222 - dense_class_td_acc: 0.9889\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Bootstrap : Using [0]lo:127.0.0.1<0> [1]eth0:172.17.0.2<0>\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO NET/IB : No device found.\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0> [1]eth0:172.17.0.2<0>\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Using network Socket\n",
      "NCCL version 2.7.8+cuda11.1\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 00/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 01/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 02/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 03/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 04/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 05/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 06/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 07/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 08/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 09/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 10/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 11/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 12/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 13/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 14/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 15/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 16/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 17/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 18/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 19/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 20/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 21/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 22/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 23/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 24/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 25/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 26/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 27/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 28/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 29/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 30/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Channel 31/32 :    0\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [1] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [2] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [3] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [4] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [5] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [6] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [7] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [8] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [9] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [10] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [11] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [12] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [13] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [14] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [15] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [16] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [17] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [18] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [19] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [20] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [21] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [22] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [23] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [24] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [25] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [26] -1/-1/-1->0->-1|-1->0->\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "1a99031ed061:1383:1411 [0] NCCL INFO comm 0x7f2d98328660 rank 0 nranks 1 cudaDev 0 busId 1000 - Init COMPLETE\n",
      "Doing validation at epoch 1(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:06<00:00, 21.85it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9740              0.1164              0.9856              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9740              \n",
      "Validation done!\n",
      "Epoch 2/20\n",
      "861/861 [==============================] - 73s 85ms/step - loss: 0.2722 - rpn_out_class_loss: 0.0093 - rpn_out_regress_loss: 0.0028 - dense_class_td_loss: 0.0246 - dense_regress_td_loss: 0.0273 - dense_class_td_acc: 0.9877\n",
      "Doing validation at epoch 2(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 29.55it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9640              0.0687              0.9784              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9640              \n",
      "Validation done!\n",
      "Epoch 3/20\n",
      "861/861 [==============================] - 74s 86ms/step - loss: 0.2779 - rpn_out_class_loss: 0.0110 - rpn_out_regress_loss: 0.0033 - dense_class_td_loss: 0.0298 - dense_regress_td_loss: 0.0334 - dense_class_td_acc: 0.9855\n",
      "Doing validation at epoch 3(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 29.59it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9685              0.1476              0.9856              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9685              \n",
      "Validation done!\n",
      "Epoch 4/20\n",
      "861/861 [==============================] - 72s 84ms/step - loss: 0.2629 - rpn_out_class_loss: 0.0103 - rpn_out_regress_loss: 0.0032 - dense_class_td_loss: 0.0264 - dense_regress_td_loss: 0.0306 - dense_class_td_acc: 0.9867\n",
      "Doing validation at epoch 4(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 30.03it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9526              0.2090              0.9712              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9526              \n",
      "Validation done!\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861/861 [==============================] - 72s 83ms/step - loss: 0.2616 - rpn_out_class_loss: 0.0108 - rpn_out_regress_loss: 0.0031 - dense_class_td_loss: 0.0300 - dense_regress_td_loss: 0.0326 - dense_class_td_acc: 0.9855\n",
      "Doing validation at epoch 5(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 29.90it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9604              0.2045              0.9712              0.9856              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9604              \n",
      "Validation done!\n",
      "Epoch 6/20\n",
      "861/861 [==============================] - 75s 87ms/step - loss: 0.2498 - rpn_out_class_loss: 0.0107 - rpn_out_regress_loss: 0.0033 - dense_class_td_loss: 0.0278 - dense_regress_td_loss: 0.0298 - dense_class_td_acc: 0.9864\n",
      "Doing validation at epoch 6(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 28.65it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9586              0.1163              0.9712              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9586              \n",
      "Validation done!\n",
      "Epoch 7/20\n",
      "861/861 [==============================] - 72s 84ms/step - loss: 0.2374 - rpn_out_class_loss: 0.0100 - rpn_out_regress_loss: 0.0031 - dense_class_td_loss: 0.0248 - dense_regress_td_loss: 0.0278 - dense_class_td_acc: 0.9877\n",
      "Doing validation at epoch 7(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 30.48it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9619              0.0760              0.9712              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9619              \n",
      "Validation done!\n",
      "Epoch 8/20\n",
      "861/861 [==============================] - 73s 85ms/step - loss: 0.2399 - rpn_out_class_loss: 0.0110 - rpn_out_regress_loss: 0.0032 - dense_class_td_loss: 0.0285 - dense_regress_td_loss: 0.0317 - dense_class_td_acc: 0.9859\n",
      "Doing validation at epoch 8(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 29.58it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9588              0.0780              0.9784              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9588              \n",
      "Validation done!\n",
      "Epoch 9/20\n",
      "861/861 [==============================] - 72s 84ms/step - loss: 0.2259 - rpn_out_class_loss: 0.0099 - rpn_out_regress_loss: 0.0030 - dense_class_td_loss: 0.0246 - dense_regress_td_loss: 0.0279 - dense_class_td_acc: 0.9877\n",
      "Doing validation at epoch 9(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 30.26it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9894              0.1434              1.0000              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9894              \n",
      "Validation done!\n",
      "Epoch 10/20\n",
      "861/861 [==============================] - 76s 88ms/step - loss: 0.2211 - rpn_out_class_loss: 0.0102 - rpn_out_regress_loss: 0.0030 - dense_class_td_loss: 0.0252 - dense_regress_td_loss: 0.0279 - dense_class_td_acc: 0.9874\n",
      "Doing validation at epoch 10(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 26.97it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9725              0.1730              0.9856              0.9856              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9725              \n",
      "Validation done!\n",
      "Epoch 11/20\n",
      "861/861 [==============================] - 79s 92ms/step - loss: 0.2126 - rpn_out_class_loss: 0.0097 - rpn_out_regress_loss: 0.0031 - dense_class_td_loss: 0.0246 - dense_regress_td_loss: 0.0255 - dense_class_td_acc: 0.9876\n",
      "Doing validation at epoch 11(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 26.98it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9917              0.1490              0.9928              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9917              \n",
      "Validation done!\n",
      "Epoch 12/20\n",
      "861/861 [==============================] - 79s 92ms/step - loss: 0.2034 - rpn_out_class_loss: 0.0088 - rpn_out_regress_loss: 0.0028 - dense_class_td_loss: 0.0228 - dense_regress_td_loss: 0.0244 - dense_class_td_acc: 0.9885\n",
      "Doing validation at epoch 12(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 26.81it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9614              0.1545              0.9856              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9614              \n",
      "Validation done!\n",
      "Epoch 13/20\n",
      "861/861 [==============================] - 79s 92ms/step - loss: 0.2041 - rpn_out_class_loss: 0.0092 - rpn_out_regress_loss: 0.0029 - dense_class_td_loss: 0.0251 - dense_regress_td_loss: 0.0269 - dense_class_td_acc: 0.9874\n",
      "Doing validation at epoch 13(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 26.86it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9763              0.1679              0.9928              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9763              \n",
      "Validation done!\n",
      "Epoch 14/20\n",
      "861/861 [==============================] - 79s 92ms/step - loss: 0.1964 - rpn_out_class_loss: 0.0088 - rpn_out_regress_loss: 0.0030 - dense_class_td_loss: 0.0232 - dense_regress_td_loss: 0.0255 - dense_class_td_acc: 0.9882\n",
      "Doing validation at epoch 14(1-based index)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 26.68it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9576              0.0355              0.9856              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9576              \n",
      "Validation done!\n",
      "Epoch 15/20\n",
      "861/861 [==============================] - 80s 93ms/step - loss: 0.2012 - rpn_out_class_loss: 0.0103 - rpn_out_regress_loss: 0.0032 - dense_class_td_loss: 0.0262 - dense_regress_td_loss: 0.0291 - dense_class_td_acc: 0.9871\n",
      "Doing validation at epoch 15(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 26.64it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9474              0.1335              0.9712              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9474              \n",
      "Validation done!\n",
      "Epoch 16/20\n",
      "861/861 [==============================] - 77s 89ms/step - loss: 0.1861 - rpn_out_class_loss: 0.0088 - rpn_out_regress_loss: 0.0027 - dense_class_td_loss: 0.0219 - dense_regress_td_loss: 0.0238 - dense_class_td_acc: 0.9891\n",
      "Doing validation at epoch 16(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 30.51it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9787              0.1785              0.9928              0.9856              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9787              \n",
      "Validation done!\n",
      "Epoch 17/20\n",
      "861/861 [==============================] - 72s 84ms/step - loss: 0.1698 - rpn_out_class_loss: 0.0069 - rpn_out_regress_loss: 0.0018 - dense_class_td_loss: 0.0178 - dense_regress_td_loss: 0.0166 - dense_class_td_acc: 0.9905\n",
      "Doing validation at epoch 17(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 30.55it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9917              0.2383              0.9928              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9917              \n",
      "Validation done!\n",
      "Epoch 18/20\n",
      "861/861 [==============================] - 73s 84ms/step - loss: 0.1660 - rpn_out_class_loss: 0.0065 - rpn_out_regress_loss: 0.0016 - dense_class_td_loss: 0.0166 - dense_regress_td_loss: 0.0153 - dense_class_td_acc: 0.9912\n",
      "Doing validation at epoch 18(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 30.37it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9823              0.2491              0.9856              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9823              \n",
      "Validation done!\n",
      "Epoch 19/20\n",
      "861/861 [==============================] - 72s 84ms/step - loss: 0.1632 - rpn_out_class_loss: 0.0060 - rpn_out_regress_loss: 0.0014 - dense_class_td_loss: 0.0159 - dense_regress_td_loss: 0.0140 - dense_class_td_acc: 0.9913\n",
      "Doing validation at epoch 19(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 29.98it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9833              0.2630              0.9856              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9833              \n",
      "Validation done!\n",
      "Epoch 20/20\n",
      "861/861 [==============================] - 72s 84ms/step - loss: 0.1629 - rpn_out_class_loss: 0.0059 - rpn_out_regress_loss: 0.0014 - dense_class_td_loss: 0.0159 - dense_regress_td_loss: 0.0140 - dense_class_td_acc: 0.9916\n",
      "Doing validation at epoch 20(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:04<00:00, 30.20it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9919              0.2619              0.9928              1.0000              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9919              \n",
      "Validation done!\n"
     ]
    }
   ],
   "source": [
    "# Retraining using the pruned model as pretrained weights \n",
    "!faster_rcnn train --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec_custom.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3.9G\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:21 frcnn_kitti_resnet18_retrain.epoch20.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:20 frcnn_kitti_resnet18_retrain.epoch19.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:19 frcnn_kitti_resnet18_retrain.epoch18.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:17 frcnn_kitti_resnet18_retrain.epoch17.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:16 frcnn_kitti_resnet18_retrain.epoch16.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:15 frcnn_kitti_resnet18_retrain.epoch15.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:13 frcnn_kitti_resnet18_retrain.epoch14.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:12 frcnn_kitti_resnet18_retrain.epoch13.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:10 frcnn_kitti_resnet18_retrain.epoch12.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:09 frcnn_kitti_resnet18_retrain.epoch11.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:08 frcnn_kitti_resnet18_retrain.epoch10.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:06 frcnn_kitti_resnet18_retrain.epoch9.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:05 frcnn_kitti_resnet18_retrain.epoch8.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:04 frcnn_kitti_resnet18_retrain.epoch7.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:02 frcnn_kitti_resnet18_retrain.epoch6.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:01 frcnn_kitti_resnet18_retrain.epoch5.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 17:00 frcnn_kitti_resnet18_retrain.epoch4.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:58 frcnn_kitti_resnet18_retrain.epoch3.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:57 frcnn_kitti_resnet18_retrain.epoch2.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:56 frcnn_kitti_resnet18_retrain.epoch1.tlt\r\n",
      "-rw-r--r-- 1 root root 49M Mar 22 16:34 model_1_pruned.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:27 frcnn_kitti_resnet18.epoch20.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:26 frcnn_kitti_resnet18.epoch19.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:24 frcnn_kitti_resnet18.epoch18.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:23 frcnn_kitti_resnet18.epoch17.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:22 frcnn_kitti_resnet18.epoch16.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:20 frcnn_kitti_resnet18.epoch15.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:19 frcnn_kitti_resnet18.epoch14.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:18 frcnn_kitti_resnet18.epoch13.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:16 frcnn_kitti_resnet18.epoch12.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:15 frcnn_kitti_resnet18.epoch11.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:14 frcnn_kitti_resnet18.epoch10.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:12 frcnn_kitti_resnet18.epoch9.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:11 frcnn_kitti_resnet18.epoch8.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:10 frcnn_kitti_resnet18.epoch7.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:08 frcnn_kitti_resnet18.epoch6.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:07 frcnn_kitti_resnet18.epoch5.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:06 frcnn_kitti_resnet18.epoch4.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:04 frcnn_kitti_resnet18.epoch3.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:03 frcnn_kitti_resnet18.epoch2.tlt\r\n",
      "-rw-r--r-- 1 root root 97M Mar 22 16:02 frcnn_kitti_resnet18.epoch1.tlt\r\n"
     ]
    }
   ],
   "source": [
    "# Listing the newly retrained model.\n",
    "!ls -lht $USER_EXPERIMENT_DIR/data/kitti/noctuidae/faster_rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7. Evaluate retrained model <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "2021-03-22 17:24:13,787 [INFO] iva.faster_rcnn.spec_loader.spec_loader: Loading experiment spec at ./specs/default_spec_resnet18_retrain_spec_custom.txt.\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/evaluate.py:60: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2021-03-22 17:24:13,810 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/evaluate.py:60: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/evaluate.py:62: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-03-22 17:24:13,810 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/evaluate.py:62: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2021-03-22 17:24:14,135 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-22 17:24:14,135 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-22 17:24:14,135 [INFO] __main__: Running evaluation with TLT as backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-03-22 17:24:14,877 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2021-03-22 17:24:14,903 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2021-03-22 17:24:14,919 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "2021-03-22 17:24:15,414 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:77: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "2021-03-22 17:24:15,417 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:77: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "2021-03-22 17:24:15,591 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "2021-03-22 17:24:15,836 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "2021-03-22 17:24:15,887 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-03-22 17:24:16,106 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2021-03-22 17:24:16,294 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2021-03-22 17:24:16,294 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2021-03-22 17:24:16,294 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-03-22 17:24:16,458 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-03-22 17:24:16,766 [INFO] __main__: Building evaluation model, may take a while...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "2021-03-22 17:24:38,608 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2021-03-22 17:24:38,662 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 3, 384, 1248) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 192, 624) 7056        input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 48, 192, 624) 192         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 192, 624) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 96, 312)  27648       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 96, 312)  0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 96, 312)  36864       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 96, 312)  3072        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 96, 312)  0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 96, 312)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 96, 312)  36864       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 96, 312)  0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 96, 312)  36864       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 96, 312)  4096        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 96, 312)  0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 96, 312)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 48, 156) 73728       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 48, 156) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 48, 156) 147456      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 48, 156) 8192        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 48, 156) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 48, 156) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 48, 156) 147456      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 48, 156) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 48, 156) 147456      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 48, 156) 16384       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 48, 156) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 48, 156) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 24, 78)  294912      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 24, 78)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 24, 78)  589824      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 24, 78)  32768       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 24, 78)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 24, 78)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 24, 78)  589824      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 24, 78)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 24, 78)  589824      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 24, 78)  65536       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 24, 78)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 24, 78)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rpn_conv1 (Conv2D)              (None, 512, 24, 78)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_class (Conv2D)          (None, 9, 24, 78)    4617        rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_regress (Conv2D)        (None, 36, 24, 78)   18468       rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "proposal_1 (Proposal)           (None, 300, 4)       0           rpn_out_class[0][0]              \n",
      "                                                                 rpn_out_regress[0][0]            \n",
      "                                                                 input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "crop_and_resize_1 (CropAndResiz (None, 300, 256, 7,  0           block_3b_relu[0][0]              \n",
      "                                                                 proposal_1[0][0]                 \n",
      "                                                                 input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 300, 512, 7,  1179648     crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 300, 512, 7,  0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 300, 512, 7,  2359296     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 300, 512, 7,  131072      crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 300, 512, 7,  0           time_distributed_4[0][0]         \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 300, 512, 7,  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 300, 512, 7,  2359296     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 300, 512, 7,  0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 300, 512, 7,  2359296     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 300, 512, 7,  262144      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 300, 512, 7,  2048        time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 300, 512, 7,  2048        time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 300, 512, 7,  0           time_distributed_10[0][0]        \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 300, 512, 7,  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 300, 512, 1,  0           block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_flatten (TimeD (None, 300, 512)     0           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_class_td (TimeDistributed (None, 300, 2)       1026        time_distributed_flatten[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_regress_td (TimeDistribut (None, 300, 4)       2052        time_distributed_flatten[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "output_parser_1 (OutputParser)  [(None, 100, 4), (No 0           proposal_1[0][0]                 \n",
      "                                                                 dense_class_td[0][0]             \n",
      "                                                                 dense_regress_td[0][0]           \n",
      "                                                                 input_image[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 12,736,131\n",
      "Trainable params: 12,572,051\n",
      "Non-trainable params: 164,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-22 17:24:40,112 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-03-22 17:24:40,112 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-03-22 17:24:40,112 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-03-22 17:24:40,112 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 12, io threads: 24, compute threads: 12, buffered batches: 4\n",
      "2021-03-22 17:24:40,112 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 140, number of sources: 1, batch size per gpu: 1, steps: 140\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f32281b7400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f32281b7400>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 17:24:40,175 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f32281b7400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f32281b7400>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 17:24:40,191 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-03-22 17:24:40,404 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2021-03-22 17:24:40,409 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-03-22 17:24:40,409 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f31ac5d0358>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f31ac5d0358>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-22 17:24:40,420 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f31ac5d0358>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f31ac5d0358>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:22: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "2021-03-22 17:24:40,800 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:22: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:23: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "2021-03-22 17:24:40,800 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:23: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:24: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "2021-03-22 17:24:40,800 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:24: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "100%|█████████████████████████████████████████| 140/140 [00:07<00:00, 18.37it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.9919              0.2654              0.9928              0.9928              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.9919              \n"
     ]
    }
   ],
   "source": [
    "!faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec_custom.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8. Visualize inferences <a class=\"anchor\" id=\"head-8\"></a>\n",
    " In this section, we run the inference tool to generate inferences on the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/inference.py:52: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2021-03-22 17:25:36,260 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/inference.py:52: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/inference.py:54: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-03-22 17:25:36,260 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/inference.py:54: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2021-03-22 17:25:36,525 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2021-03-22 17:25:36,526 [INFO] iva.faster_rcnn.spec_loader.spec_loader: Loading experiment spec at ./specs/default_spec_resnet18_retrain_spec_custom.txt.\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-22 17:25:36,538 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-22 17:25:36,538 [INFO] __main__: Running inference with TLT as backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-03-22 17:25:37,276 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2021-03-22 17:25:37,312 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2021-03-22 17:25:37,331 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "2021-03-22 17:25:37,802 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:77: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "2021-03-22 17:25:37,804 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:77: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "2021-03-22 17:25:37,978 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "2021-03-22 17:25:38,224 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "2021-03-22 17:25:38,274 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-03-22 17:25:38,487 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2021-03-22 17:25:38,673 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2021-03-22 17:25:38,674 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2021-03-22 17:25:38,674 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-03-22 17:25:38,841 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-03-22 17:25:39,148 [INFO] __main__: Building inference model, may take a while...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "2021-03-22 17:26:00,843 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2021-03-22 17:26:00,923 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 3, 384, 1248) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 192, 624) 7056        input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 48, 192, 624) 192         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 192, 624) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 96, 312)  27648       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 96, 312)  0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 96, 312)  36864       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 96, 312)  3072        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 96, 312)  0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 96, 312)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 96, 312)  36864       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 96, 312)  0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 96, 312)  36864       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 96, 312)  4096        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 96, 312)  0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 96, 312)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 48, 156) 73728       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 48, 156) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 48, 156) 147456      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 48, 156) 8192        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 48, 156) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 48, 156) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 48, 156) 147456      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 48, 156) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 48, 156) 147456      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 48, 156) 16384       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 48, 156) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 48, 156) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 24, 78)  294912      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 24, 78)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 24, 78)  589824      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 24, 78)  32768       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 24, 78)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 24, 78)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 24, 78)  589824      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 24, 78)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 24, 78)  589824      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 24, 78)  65536       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 24, 78)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 24, 78)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rpn_conv1 (Conv2D)              (None, 512, 24, 78)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_class (Conv2D)          (None, 9, 24, 78)    4617        rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_regress (Conv2D)        (None, 36, 24, 78)   18468       rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "proposal_1 (Proposal)           (None, 300, 4)       0           rpn_out_class[0][0]              \n",
      "                                                                 rpn_out_regress[0][0]            \n",
      "                                                                 input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "crop_and_resize_1 (CropAndResiz (None, 300, 256, 7,  0           block_3b_relu[0][0]              \n",
      "                                                                 proposal_1[0][0]                 \n",
      "                                                                 input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 300, 512, 7,  1179648     crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 300, 512, 7,  0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 300, 512, 7,  2359296     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 300, 512, 7,  131072      crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 300, 512, 7,  0           time_distributed_4[0][0]         \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 300, 512, 7,  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 300, 512, 7,  2359296     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 300, 512, 7,  2048        time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 300, 512, 7,  0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 300, 512, 7,  2359296     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 300, 512, 7,  262144      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 300, 512, 7,  2048        time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 300, 512, 7,  2048        time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 300, 512, 7,  0           time_distributed_10[0][0]        \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 300, 512, 7,  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 300, 512, 1,  0           block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_flatten (TimeD (None, 300, 512)     0           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_class_td (TimeDistributed (None, 300, 2)       1026        time_distributed_flatten[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_regress_td (TimeDistribut (None, 300, 4)       2052        time_distributed_flatten[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "output_parser_1 (OutputParser)  [(None, 100, 4), (No 0           proposal_1[0][0]                 \n",
      "                                                                 dense_class_td[0][0]             \n",
      "                                                                 dense_regress_td[0][0]           \n",
      "                                                                 input_image[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 12,736,131\n",
      "Trainable params: 12,572,051\n",
      "Non-trainable params: 164,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3998/3998 [04:40<00:00, 14.23it/s]\n",
      "2021-03-22 17:30:43,247 [INFO] __main__: Inference output images directory: /workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/inference_results_imgs_retrain\n",
      "2021-03-22 17:30:43,247 [INFO] __main__: Inference output labels directory: /workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/inference_dump_labels_retrain\n"
     ]
    }
   ],
   "source": [
    "# Running inference for detection on n images\n",
    "# Please go to $USER_EXPERIMENT_DIR/data/faster_rcnn/inference_results_imgs_retrain to see the visualizations.\n",
    "!faster_rcnn inference --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec_custom.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inference` tool produces two outputs. \n",
    "1. Overlain images in `$USER_EXPERIMENT_DIR/data/kitti/NAME/faster_rcnn/inference_results_imgs_retrain`\n",
    "2. Frame by frame bbox labels in kitti format located in `$USER_EXPERIMENT_DIR/data/kitti/NAME/faster_rcnn/inference_dump_labels_retrain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grid visualizer\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from math import ceil\n",
    "valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n",
    "\n",
    "def visualize_images(image_dir, num_cols=4, num_images=10):\n",
    "    output_path = os.path.join(os.environ['USER_EXPERIMENT_DIR'], image_dir)\n",
    "    num_rows = int(ceil(float(num_images) / float(num_cols)))\n",
    "    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n",
    "    f.tight_layout()\n",
    "    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n",
    "         if os.path.splitext(image)[1].lower() in valid_image_ext]\n",
    "    for idx, img_path in enumerate(a[:num_images]):\n",
    "        col_id = idx % num_cols\n",
    "        row_id = idx // num_cols\n",
    "        img = plt.imread(img_path)\n",
    "        axarr[row_id, col_id].imshow(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/inference_results_imgs_retrain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-0a3e85bd0947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mIMAGES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m18\u001b[0m \u001b[0;31m# number of images to visualize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvisualize_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-003db1cc3a70>\u001b[0m in \u001b[0;36mvisualize_images\u001b[0;34m(image_dir, num_cols, num_images)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n\u001b[0m\u001b[1;32m     14\u001b[0m          if os.path.splitext(image)[1].lower() in valid_image_ext]\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/workspace/tlt-experiments/insect-thesis/data/kitti/noctuidae/faster_rcnn/inference_results_imgs_retrain'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 5760x2160 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the sample images.\n",
    "OUTPUT_PATH = 'data/kitti/noctuidae/faster_rcnn/inference_results_imgs_retrain' # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 3 # number of columns in the visualizer grid.\n",
    "IMAGES = 18 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 9. Deploy! <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export in FP32 mode.\n",
    "!if [ -f $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain.etlt ]; then rm $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain.etlt; fi\n",
    "!faster_rcnn export --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain.epoch12.tlt  \\\n",
    "                        -o $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain.etlt \\\n",
    "                        -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt \\\n",
    "                        -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export in FP16 mode.\n",
    "# Note that the .etlt model in FP16 mode is the same as in FP32 mode.\n",
    "!if [ -f $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_fp16.etlt ]; then rm $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_fp16.etlt; fi\n",
    "!faster_rcnn export --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain.epoch12.tlt  \\\n",
    "                        -o $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_fp16.etlt \\\n",
    "                        -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt \\\n",
    "                        -k $KEY \\\n",
    "                        --data_type fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export in INT8 mode(generate calibration cache file).\n",
    "# Note that the .etlt model in INT8 mode is the same as in FP32 mode.\n",
    "!if [ -f $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_int8.etlt ]; then rm $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_int8.etlt; fi\n",
    "!faster_rcnn export --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain.epoch12.tlt  \\\n",
    "                        -o $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_int8.etlt \\\n",
    "                        -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt \\\n",
    "                        -k $KEY \\\n",
    "                        --data_type int8 \\\n",
    "                        --batch_size 8 \\\n",
    "                        --batches 10 \\\n",
    "                        --cal_cache_file $USER_EXPERIMENT_DIR/data/faster_rcnn/cal.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to TensorRT engine(FP32) is omitted here as this is trivial.\n",
    "# Convert to TensorRT engine(FP16).\n",
    "# Make sure your GPU type supports the FP16 data type before running this cell.\n",
    "!CUDA_VISIBLE_DEVICES=$GPU_INDEX tlt-converter -k $KEY  \\\n",
    "               -d 3,384,1248 \\\n",
    "               -o NMS \\\n",
    "               -e $USER_EXPERIMENT_DIR/data/faster_rcnn/trt.fp16.engine \\\n",
    "               -m 4 \\\n",
    "               -t fp16 \\\n",
    "               -i nchw \\\n",
    "               $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_fp16.etlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorRT engine(INT8).\n",
    "# Make sure your GPU type supports the INT8 data type before running this cell.\n",
    "!CUDA_VISIBLE_DEVICES=$GPU_INDEX tlt-converter -k $KEY  \\\n",
    "               -d 3,384,1248 \\\n",
    "               -o NMS \\\n",
    "               -c $USER_EXPERIMENT_DIR/data/faster_rcnn/cal.bin \\\n",
    "               -e $USER_EXPERIMENT_DIR/data/faster_rcnn/trt.int8.engine \\\n",
    "               -b 8 \\\n",
    "               -m 4 \\\n",
    "               -t int8 \\\n",
    "               -i nchw \\\n",
    "               $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_int8.etlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exported model and converted TensorRT engine:')\n",
    "print('------------')\n",
    "!ls -lht $USER_EXPERIMENT_DIR/data/faster_rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do inference with TensorRT on the generated TensorRT engine\n",
    "# Please go to $USER_EXPERIMENT_DIR/data/faster_rcnn/inference_results_imgs_retrain to see the visualizations.\n",
    "# Here we use the INT8 engine for inference, if you want to use FP16 engine instead please\n",
    "# customize the 'trt_engine' parameter in the spec file below to point to the FP16 engine.\n",
    "!TRT_LINES=$(grep -n 'trt_inference' $SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/#//g\\n' $(seq $TRT_LINES $((TRT_LINES+4))) | sed -i -f - $SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n",
    "!faster_rcnn inference --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inference` tool produces two outputs. \n",
    "The paths to the two outputs are exactly the same as the first `inference` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the sample images from TensorRT inference.\n",
    "OUTPUT_PATH = 'data/faster_rcnn/inference_results_imgs_retrain' # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 3 # number of columns in the visualizer grid.\n",
    "IMAGES = 9 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing evaluation with the generated TensorRT engine\n",
    "# modify the spec file a little for tensorrt_evaluation configuration\n",
    "# compare the mAP below with that of `evaluate` with retrained tlt model\n",
    "!TRT_LINES=$(grep -n 'trt_evaluation' $SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/#//g\\n' $(seq $TRT_LINES $((TRT_LINES+4))) | sed -i -f - $SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n",
    "# do evaluation with tensorrt engine\n",
    "!faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 10. QAT workflow <a class=\"anchor\" id=\"head-10\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will explore the typical Quantization-Aware Training(QAT) workflow with TLT. QAT workflow is almost the same as non-QAT workflow except for two major differences:\n",
    "1. set `enable_qat` to `True` in training and retraining spec files to enable the QAT for training/retraining\n",
    "2. when doing export in INT8 mode, the calibration cache is extracted directly from the QAT .tlt model, so no need to specify any TensorRT INT8 calibration related arguments for `export`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 10.1. Training <a class=\"anchor\" id=\"head-10.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2017-2020, NVIDIA CORPORATION.  All rights reserved.\r\n",
      "random_seed: 42\r\n",
      "enc_key: 'cmV1b2gzMjJnNjRpbGc2Yms0dGIwZmtwdmw6YmE1ZGJkN2YtNzZkMC00OGE0LWE1N2ItNzc2Y2VjMGYwZDk0'\r\n",
      "verbose: True\r\n",
      "model_config {\r\n",
      "input_image_config {\r\n",
      "image_type: RGB\r\n",
      "image_channel_order: 'bgr'\r\n",
      "size_height_width {\r\n",
      "height: 384\r\n",
      "width: 1248\r\n",
      "}\r\n",
      "    image_channel_mean {\r\n",
      "        key: 'b'\r\n",
      "        value: 103.939\r\n",
      "}\r\n",
      "    image_channel_mean {\r\n",
      "        key: 'g'\r\n",
      "        value: 116.779\r\n",
      "}\r\n",
      "    image_channel_mean {\r\n",
      "        key: 'r'\r\n",
      "        value: 123.68\r\n",
      "}\r\n",
      "image_scaling_factor: 1.0\r\n",
      "max_objects_num_per_image: 100\r\n",
      "}\r\n",
      "arch: \"resnet:18\"\r\n",
      "anchor_box_config {\r\n",
      "scale: 64.0\r\n",
      "scale: 128.0\r\n",
      "scale: 256.0\r\n",
      "ratio: 1.0\r\n",
      "ratio: 0.5\r\n",
      "ratio: 2.0\r\n",
      "}\r\n",
      "freeze_bn: True\r\n",
      "freeze_blocks: 0\r\n",
      "freeze_blocks: 1\r\n",
      "roi_mini_batch: 256\r\n",
      "rpn_stride: 16\r\n",
      "use_bias: False\r\n",
      "roi_pooling_config {\r\n",
      "pool_size: 7\r\n",
      "pool_size_2x: False\r\n",
      "}\r\n",
      "all_projections: True\r\n",
      "use_pooling:False\r\n",
      "}\r\n",
      "dataset_config {\r\n",
      "  data_sources: {\r\n",
      "    tfrecords_path: \"/workspace/tlt-experiments/tfrecords/kitti_trainval/kitti_trainval*\"\r\n",
      "    image_directory_path: \"/workspace/tlt-experiments/data/kitti/noctuidae/train\"\r\n",
      "  }\r\n",
      "image_extension: 'jpg'\r\n",
      "target_class_mapping {\r\n",
      "key: 'noctuidae'\r\n",
      "value: 'noctuidae'\r\n",
      "}\r\n",
      "\r\n",
      "validation_fold: 0\r\n",
      "}\r\n",
      "augmentation_config {\r\n",
      "preprocessing {\r\n",
      "output_image_width: 1248\r\n",
      "output_image_height: 384\r\n",
      "output_image_channel: 3\r\n",
      "min_bbox_width: 1.0\r\n",
      "min_bbox_height: 1.0\r\n",
      "}\r\n",
      "spatial_augmentation {\r\n",
      "hflip_probability: 0.5\r\n",
      "vflip_probability: 0.0\r\n",
      "zoom_min: 1.0\r\n",
      "zoom_max: 1.0\r\n",
      "translate_max_x: 0\r\n",
      "translate_max_y: 0\r\n",
      "}\r\n",
      "color_augmentation {\r\n",
      "hue_rotation_max: 0.0\r\n",
      "saturation_shift_max: 0.0\r\n",
      "contrast_scale_max: 0.0\r\n",
      "contrast_center: 0.5\r\n",
      "}\r\n",
      "}\r\n",
      "training_config {\r\n",
      "enable_augmentation: True\r\n",
      "enable_qat: True\r\n",
      "batch_size_per_gpu: 1\r\n",
      "num_epochs: 12\r\n",
      "pretrained_weights: \"/workspace/tlt-experiments/data/faster_rcnn/resnet_18.hdf5\"\r\n",
      "#resume_from_model: \"/workspace/tlt-experiments/data/faster_rcnn/resnet18.epoch2.tlt\"\r\n",
      "output_model: \"/workspace/tlt-experiments/data/faster_rcnn/frcnn_kitti_resnet18.tlt\"\r\n",
      "rpn_min_overlap: 0.3\r\n",
      "rpn_max_overlap: 0.7\r\n",
      "classifier_min_overlap: 0.0\r\n",
      "classifier_max_overlap: 0.5\r\n",
      "gt_as_roi: False\r\n",
      "std_scaling: 1.0\r\n",
      "classifier_regr_std {\r\n",
      "key: 'x'\r\n",
      "value: 10.0\r\n",
      "}\r\n",
      "classifier_regr_std {\r\n",
      "key: 'y'\r\n",
      "value: 10.0\r\n",
      "}\r\n",
      "classifier_regr_std {\r\n",
      "key: 'w'\r\n",
      "value: 5.0\r\n",
      "}\r\n",
      "classifier_regr_std {\r\n",
      "key: 'h'\r\n",
      "value: 5.0\r\n",
      "}\r\n",
      "\r\n",
      "rpn_mini_batch: 256\r\n",
      "rpn_pre_nms_top_N: 12000\r\n",
      "rpn_nms_max_boxes: 2000\r\n",
      "rpn_nms_overlap_threshold: 0.7\r\n",
      "\r\n",
      "regularizer {\r\n",
      "type: L2\r\n",
      "weight: 1e-4\r\n",
      "}\r\n",
      "\r\n",
      "optimizer {\r\n",
      "sgd {\r\n",
      "lr: 0.02\r\n",
      "momentum: 0.9\r\n",
      "decay: 0.0\r\n",
      "nesterov: False\r\n",
      "}\r\n",
      "}\r\n",
      "\r\n",
      "learning_rate {\r\n",
      "soft_start {\r\n",
      "base_lr: 0.02\r\n",
      "start_lr: 0.002\r\n",
      "soft_start: 0.1\r\n",
      "annealing_points: 0.8\r\n",
      "annealing_points: 0.9\r\n",
      "annealing_divider: 10.0\r\n",
      "}\r\n",
      "}\r\n",
      "\r\n",
      "lambda_rpn_regr: 1.0\r\n",
      "lambda_rpn_class: 1.0\r\n",
      "lambda_cls_regr: 1.0\r\n",
      "lambda_cls_class: 1.0\r\n",
      "}\r\n",
      "inference_config {\r\n",
      "images_dir: '/workspace/tlt-experiments/data/kitti/noctuidae/test/images'\r\n",
      "model: '/workspace/tlt-experiments/data/faster_rcnn/frcnn_kitti_resnet18.epoch12.tlt'\r\n",
      "batch_size: 1\r\n",
      "detection_image_output_dir: '/workspace/tlt-experiments/data/faster_rcnn/inference_results_imgs'\r\n",
      "labels_dump_dir: '/workspace/tlt-experiments/data/faster_rcnn/inference_dump_labels'\r\n",
      "rpn_pre_nms_top_N: 6000\r\n",
      "rpn_nms_max_boxes: 300\r\n",
      "rpn_nms_overlap_threshold: 0.7\r\n",
      "object_confidence_thres: 0.0001\r\n",
      "bbox_visualize_threshold: 0.6\r\n",
      "classifier_nms_max_boxes: 100\r\n",
      "classifier_nms_overlap_threshold: 0.3\r\n",
      "}\r\n",
      "evaluation_config {\r\n",
      "model: '/workspace/tlt-experiments/data/faster_rcnn/frcnn_kitti_resnet18.epoch12.tlt'\r\n",
      "batch_size: 1\r\n",
      "validation_period_during_training: 1\r\n",
      "labels_dump_dir: '/workspace/tlt-experiments/data/faster_rcnn/test_dump_labels'\r\n",
      "rpn_pre_nms_top_N: 6000\r\n",
      "rpn_nms_max_boxes: 300\r\n",
      "rpn_nms_overlap_threshold: 0.7\r\n",
      "classifier_nms_max_boxes: 100\r\n",
      "classifier_nms_overlap_threshold: 0.3\r\n",
      "object_confidence_thres: 0.0001\r\n",
      "use_voc07_11point_metric:False\r\n",
      "gt_matching_iou_threshold: 0.5\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# set enable_qat to True in training spec file to enable QAT training\n",
    "!sed -i 's/enable_qat: False/enable_qat: True/' $SPECS_DIR/default_spec_resnet18_custom.txt\n",
    "!cat $SPECS_DIR/default_spec_resnet18_custom.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2021-03-20 14:47:31,514 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2021-03-20 14:47:31,514 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:47: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2021-03-20 14:47:31,573 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:47: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-03-20 14:47:31,573 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-03-20 14:47:31,825 [INFO] iva.faster_rcnn.spec_loader.spec_loader: Loading experiment spec at ./specs/default_spec_resnet18_custom.txt.\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-20 14:47:31,831 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:381: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2021-03-20 14:47:31,966 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-03-20 14:47:31,967 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-03-20 14:47:31,967 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-03-20 14:47:31,967 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 12, io threads: 24, compute threads: 12, buffered batches: 4\n",
      "2021-03-20 14:47:31,967 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 861, number of sources: 1, batch size per gpu: 1, steps: 861\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fa2b5eed128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fa2b5eed128>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-20 14:47:32,039 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fa2b5eed128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fa2b5eed128>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-20 14:47:32,055 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-03-20 14:47:32,274 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: True - shard 0 of 1\n",
      "2021-03-20 14:47:32,279 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-03-20 14:47:32,279 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fa29fd415c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fa29fd415c0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-20 14:47:32,291 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fa29fd415c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fa29fd415c0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/data_loader/inputs_loader.py:221: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "2021-03-20 14:47:32,764 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/data_loader/inputs_loader.py:221: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2021-03-20 14:47:32,777 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "2021-03-20 14:47:33,275 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "2021-03-20 14:47:33,460 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:382: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "2021-03-20 14:47:33,702 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:255: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "2021-03-20 14:47:33,752 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:78: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-03-20 14:47:33,888 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2021-03-20 14:47:33,929 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2021-03-20 14:47:33,929 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-03-20 14:47:34,147 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2463: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-03-20 14:47:34,671 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2463: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-03-20 14:48:19,890 [INFO] __main__: Loading pretrained weights from /workspace/tlt-experiments/data/faster_rcnn/resnet_18.hdf5\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2021-03-20 14:48:20,115 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "===================================================================================================\n",
      "Pretrained weights loading status summary:\n",
      "None: layer has no weights at all.\n",
      "Yes: layer has weights and loaded successfully by name.\n",
      "No: layer has weights but names not match, skipped.\n",
      "===================================================================================================\n",
      "Layer(Type):                                                                              Status:  \n",
      "---------------------------------------------------------------------------------------------------\n",
      "input_image(InputLayer)                                                                   None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "input_image_qdq(QDQ)                                                                      No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "conv1(QuantizedConv2D)                                                                    Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "bn_conv1(BatchNormalization)                                                              Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "activation_1(ReLU)                                                                        None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "activation_1_qdq(QDQ)                                                                     No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_conv_1(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_relu_1(ReLU)                                                                     None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_relu_1_qdq(QDQ)                                                                  No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_conv_2(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_conv_shortcut(QuantizedConv2D)                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_bn_2_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_bn_shortcut_qdq(QDQ)                                                             No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_1(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_1_qdq(QDQ)                                                                            No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_relu(ReLU)                                                                       None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1a_relu_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_conv_1(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_relu_1(ReLU)                                                                     None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_relu_1_qdq(QDQ)                                                                  No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_conv_2(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_conv_shortcut(QuantizedConv2D)                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_bn_2_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_bn_shortcut_qdq(QDQ)                                                             No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_2(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_2_qdq(QDQ)                                                                            No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_relu(ReLU)                                                                       None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_1b_relu_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_conv_1(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_relu_1(ReLU)                                                                     None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_relu_1_qdq(QDQ)                                                                  No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_conv_2(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_conv_shortcut(QuantizedConv2D)                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_bn_2_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_bn_shortcut_qdq(QDQ)                                                             No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_3(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_3_qdq(QDQ)                                                                            No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_relu(ReLU)                                                                       None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2a_relu_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_conv_1(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_relu_1(ReLU)                                                                     None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_relu_1_qdq(QDQ)                                                                  No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_conv_2(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_conv_shortcut(QuantizedConv2D)                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_bn_2_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_bn_shortcut_qdq(QDQ)                                                             No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_4(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_4_qdq(QDQ)                                                                            No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_relu(ReLU)                                                                       None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_2b_relu_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_conv_1(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_relu_1(ReLU)                                                                     None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_relu_1_qdq(QDQ)                                                                  No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_conv_2(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_conv_shortcut(QuantizedConv2D)                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_bn_2_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_bn_shortcut_qdq(QDQ)                                                             No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_5(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_5_qdq(QDQ)                                                                            No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_relu(ReLU)                                                                       None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3a_relu_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_conv_1(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_bn_1(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_relu_1(ReLU)                                                                     None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_relu_1_qdq(QDQ)                                                                  No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_conv_2(QuantizedConv2D)                                                          Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_conv_shortcut(QuantizedConv2D)                                                   Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_bn_2(BatchNormalization)                                                         Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_bn_shortcut(BatchNormalization)                                                  Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_bn_2_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_bn_shortcut_qdq(QDQ)                                                             No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_6(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_6_qdq(QDQ)                                                                            No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_relu(ReLU)                                                                       None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_3b_relu_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "rpn_conv1(QuantizedConv2D)                                                                No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "re_lu_1(ReLU)                                                                             None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "rpn_conv1_act_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "rpn_out_class(Conv2D)                                                                     No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "rpn_out_regress(Conv2D)                                                                   No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "proposal_1(Proposal)                                                                      None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "input_gt_cls(InputLayer)                                                                  None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "input_gt_bbox(InputLayer)                                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "proposal_target_1(ProposalTarget)                                                         None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "crop_and_resize_1(CropAndResize)                                                          None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "crop_and_resize_1_qdq(QDQ)                                                                No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_1(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_2(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4a_relu_1(ReLU)                                                                     None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4a_relu_1_qdq(QDQ)                                                                  No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_3(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_5(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_4(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_6(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_4_qdq(QDQ)                                                               No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_6_qdq(QDQ)                                                               No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_7(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_7_qdq(QDQ)                                                                            No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4a_relu(ReLU)                                                                       None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4a_relu_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_7(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_8(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4b_relu_1(ReLU)                                                                     None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4b_relu_1_qdq(QDQ)                                                                  No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_9(TimeDistributed)                                                       Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_11(TimeDistributed)                                                      Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_10(TimeDistributed)                                                      Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_12(TimeDistributed)                                                      Yes      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_10_qdq(QDQ)                                                              No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_12_qdq(QDQ)                                                              No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_8(Add)                                                                                None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "add_8_qdq(QDQ)                                                                            No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4b_relu(ReLU)                                                                       None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "block_4b_relu_qdq(QDQ)                                                                    No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_13(TimeDistributed)                                                      None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_13_qdq(QDQ)                                                              No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_flatten(TimeDistributed)                                                 None     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "time_distributed_flatten_qdq(QDQ)                                                         No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "dense_class_td(TimeDistributed)                                                           No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "dense_regress_td(TimeDistributed)                                                         No       \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2021-03-20 14:48:28,885 [INFO] __main__: Pretrained weights loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:64: The name tf.unsorted_segment_min is deprecated. Please use tf.math.unsorted_segment_min instead.\n",
      "\n",
      "2021-03-20 14:48:29,199 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:64: The name tf.unsorted_segment_min is deprecated. Please use tf.math.unsorted_segment_min instead.\n",
      "\n",
      "2021-03-20 14:48:30,338 [INFO] __main__: Building validation dataset...\n",
      "2021-03-20 14:48:31,035 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-03-20 14:48:31,035 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-03-20 14:48:31,036 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-03-20 14:48:31,036 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 12, io threads: 24, compute threads: 12, buffered batches: 4\n",
      "2021-03-20 14:48:31,036 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 140, number of sources: 1, batch size per gpu: 1, steps: 140\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fa250524358>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fa250524358>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-20 14:48:31,045 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fa250524358>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fa250524358>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-20 14:48:31,061 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-03-20 14:48:31,269 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2021-03-20 14:48:31,273 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-03-20 14:48:31,273 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fa250343550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fa250343550>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-20 14:48:31,285 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fa250343550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fa250343550>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2021-03-20 14:48:31,655 [INFO] __main__: Validation dataset built successfully!\n",
      "2021-03-20 14:48:31,655 [INFO] iva.faster_rcnn.models.model_builder: Building validation model, may take a while...\n",
      "2021-03-20 14:52:04,067 [INFO] iva.faster_rcnn.models.model_builder: Validation model built successfully!\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-03-20 14:52:04,068 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 3, 384, 1248) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_image_qdq (QDQ)           (None, 3, 384, 1248) 1           input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (QuantizedConv2D)         (None, 64, 192, 624) 9408        input_image_qdq[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 192, 624) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (ReLU)             (None, 64, 192, 624) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1_qdq (QDQ)          (None, 64, 192, 624) 1           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (QuantizedConv2 (None, 64, 96, 312)  36864       activation_1_qdq[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (ReLU)          (None, 64, 96, 312)  0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1_qdq (QDQ)       (None, 64, 96, 312)  1           block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (QuantizedConv2 (None, 64, 96, 312)  36864       block_1a_relu_1_qdq[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Quantiz (None, 64, 96, 312)  4096        activation_1_qdq[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2_qdq (QDQ)         (None, 64, 96, 312)  1           block_1a_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut_qdq (QDQ)  (None, 64, 96, 312)  1           block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 96, 312)  0           block_1a_bn_2_qdq[0][0]          \n",
      "                                                                 block_1a_bn_shortcut_qdq[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_1_qdq (QDQ)                 (None, 64, 96, 312)  1           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (ReLU)            (None, 64, 96, 312)  0           add_1_qdq[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_qdq (QDQ)         (None, 64, 96, 312)  1           block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (QuantizedConv2 (None, 64, 96, 312)  36864       block_1a_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (ReLU)          (None, 64, 96, 312)  0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1_qdq (QDQ)       (None, 64, 96, 312)  1           block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (QuantizedConv2 (None, 64, 96, 312)  36864       block_1b_relu_1_qdq[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Quantiz (None, 64, 96, 312)  4096        block_1a_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 96, 312)  256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 96, 312)  256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2_qdq (QDQ)         (None, 64, 96, 312)  1           block_1b_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut_qdq (QDQ)  (None, 64, 96, 312)  1           block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 96, 312)  0           block_1b_bn_2_qdq[0][0]          \n",
      "                                                                 block_1b_bn_shortcut_qdq[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_2_qdq (QDQ)                 (None, 64, 96, 312)  1           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (ReLU)            (None, 64, 96, 312)  0           add_2_qdq[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_qdq (QDQ)         (None, 64, 96, 312)  1           block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (QuantizedConv2 (None, 128, 48, 156) 73728       block_1b_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (ReLU)          (None, 128, 48, 156) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1_qdq (QDQ)       (None, 128, 48, 156) 1           block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (QuantizedConv2 (None, 128, 48, 156) 147456      block_2a_relu_1_qdq[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Quantiz (None, 128, 48, 156) 8192        block_1b_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2_qdq (QDQ)         (None, 128, 48, 156) 1           block_2a_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut_qdq (QDQ)  (None, 128, 48, 156) 1           block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 48, 156) 0           block_2a_bn_2_qdq[0][0]          \n",
      "                                                                 block_2a_bn_shortcut_qdq[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_3_qdq (QDQ)                 (None, 128, 48, 156) 1           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (ReLU)            (None, 128, 48, 156) 0           add_3_qdq[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_qdq (QDQ)         (None, 128, 48, 156) 1           block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (QuantizedConv2 (None, 128, 48, 156) 147456      block_2a_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (ReLU)          (None, 128, 48, 156) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1_qdq (QDQ)       (None, 128, 48, 156) 1           block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (QuantizedConv2 (None, 128, 48, 156) 147456      block_2b_relu_1_qdq[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Quantiz (None, 128, 48, 156) 16384       block_2a_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 48, 156) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 48, 156) 512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2_qdq (QDQ)         (None, 128, 48, 156) 1           block_2b_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut_qdq (QDQ)  (None, 128, 48, 156) 1           block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 48, 156) 0           block_2b_bn_2_qdq[0][0]          \n",
      "                                                                 block_2b_bn_shortcut_qdq[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_4_qdq (QDQ)                 (None, 128, 48, 156) 1           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (ReLU)            (None, 128, 48, 156) 0           add_4_qdq[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_qdq (QDQ)         (None, 128, 48, 156) 1           block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (QuantizedConv2 (None, 256, 24, 78)  294912      block_2b_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (ReLU)          (None, 256, 24, 78)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1_qdq (QDQ)       (None, 256, 24, 78)  1           block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (QuantizedConv2 (None, 256, 24, 78)  589824      block_3a_relu_1_qdq[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Quantiz (None, 256, 24, 78)  32768       block_2b_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2_qdq (QDQ)         (None, 256, 24, 78)  1           block_3a_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut_qdq (QDQ)  (None, 256, 24, 78)  1           block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 24, 78)  0           block_3a_bn_2_qdq[0][0]          \n",
      "                                                                 block_3a_bn_shortcut_qdq[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_5_qdq (QDQ)                 (None, 256, 24, 78)  1           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (ReLU)            (None, 256, 24, 78)  0           add_5_qdq[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_qdq (QDQ)         (None, 256, 24, 78)  1           block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (QuantizedConv2 (None, 256, 24, 78)  589824      block_3a_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (ReLU)          (None, 256, 24, 78)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1_qdq (QDQ)       (None, 256, 24, 78)  1           block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (QuantizedConv2 (None, 256, 24, 78)  589824      block_3b_relu_1_qdq[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Quantiz (None, 256, 24, 78)  65536       block_3a_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 24, 78)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 24, 78)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2_qdq (QDQ)         (None, 256, 24, 78)  1           block_3b_bn_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut_qdq (QDQ)  (None, 256, 24, 78)  1           block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 24, 78)  0           block_3b_bn_2_qdq[0][0]          \n",
      "                                                                 block_3b_bn_shortcut_qdq[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_6_qdq (QDQ)                 (None, 256, 24, 78)  1           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (ReLU)            (None, 256, 24, 78)  0           add_6_qdq[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_qdq (QDQ)         (None, 256, 24, 78)  1           block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rpn_conv1 (QuantizedConv2D)     (None, 512, 24, 78)  1180160     block_3b_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 512, 24, 78)  0           rpn_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_conv1_act_qdq (QDQ)         (None, 512, 24, 78)  1           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_class (Conv2D)          (None, 9, 24, 78)    4617        rpn_conv1_act_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "rpn_out_regress (Conv2D)        (None, 36, 24, 78)   18468       rpn_conv1_act_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "proposal_1 (Proposal)           (None, 2000, 4)      0           rpn_out_class[0][0]              \n",
      "                                                                 rpn_out_regress[0][0]            \n",
      "                                                                 input_image_qdq[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_cls (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_bbox (InputLayer)      (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "proposal_target_1 (ProposalTarg [(None, 256, 4), (No 0           proposal_1[0][0]                 \n",
      "                                                                 input_gt_cls[0][0]               \n",
      "                                                                 input_gt_bbox[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crop_and_resize_1 (CropAndResiz (None, 256, 256, 7,  0           block_3b_relu_qdq[0][0]          \n",
      "                                                                 proposal_target_1[0][0]          \n",
      "                                                                 input_image_qdq[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "crop_and_resize_1_qdq (QDQ)     (None, 256, 256, 7,  1           crop_and_resize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 256, 512, 7,  1179648     crop_and_resize_1_qdq[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (ReLU)          (None, 256, 512, 7,  0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1_qdq (QDQ)       (None, 256, 512, 7,  1           block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 256, 512, 7,  2359296     block_4a_relu_1_qdq[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 256, 512, 7,  131072      crop_and_resize_1_qdq[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4_qdq (QDQ)    (None, 256, 512, 7,  1           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6_qdq (QDQ)    (None, 256, 512, 7,  1           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 256, 512, 7,  0           time_distributed_4_qdq[0][0]     \n",
      "                                                                 time_distributed_6_qdq[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7_qdq (QDQ)                 (None, 256, 512, 7,  1           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (ReLU)            (None, 256, 512, 7,  0           add_7_qdq[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_qdq (QDQ)         (None, 256, 512, 7,  1           block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 256, 512, 7,  2359296     block_4a_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 256, 512, 7,  2048        time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (ReLU)          (None, 256, 512, 7,  0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1_qdq (QDQ)       (None, 256, 512, 7,  1           block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 256, 512, 7,  2359296     block_4b_relu_1_qdq[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 256, 512, 7,  262144      block_4a_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 256, 512, 7,  2048        time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 256, 512, 7,  2048        time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10_qdq (QDQ)   (None, 256, 512, 7,  1           time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12_qdq (QDQ)   (None, 256, 512, 7,  1           time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 256, 512, 7,  0           time_distributed_10_qdq[0][0]    \n",
      "                                                                 time_distributed_12_qdq[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_8_qdq (QDQ)                 (None, 256, 512, 7,  1           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (ReLU)            (None, 256, 512, 7,  0           add_8_qdq[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_qdq (QDQ)         (None, 256, 512, 7,  1           block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 256, 512, 1,  0           block_4b_relu_qdq[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13_qdq (QDQ)   (None, 256, 512, 1,  1           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_flatten (TimeD (None, 256, 512)     0           time_distributed_13_qdq[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_flatten_qdq (Q (None, 256, 512)     1           time_distributed_flatten[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_class_td (TimeDistributed (None, 256, 2)       1026        time_distributed_flatten_qdq[0][0\n",
      "__________________________________________________________________________________________________\n",
      "dense_regress_td (TimeDistribut (None, 256, 4)       2052        time_distributed_flatten_qdq[0][0\n",
      "==================================================================================================\n",
      "Total params: 12,748,833\n",
      "Trainable params: 12,572,083\n",
      "Non-trainable params: 176,750\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:22: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "2021-03-20 14:52:04,208 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:22: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:23: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "2021-03-20 14:52:04,209 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:23: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:24: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "2021-03-20 14:52:04,209 [WARNING] tensorflow: From /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:24: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "2021-03-20 14:52:06,277 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "2021-03-20 14:52:06,432 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/12\n",
      "  2/861 [..............................] - ETA: 1:09:45 - loss: 1.6774 - rpn_out_class_loss: 0.6725 - rpn_out_regress_loss: 0.0486 - dense_class_td_loss: 0.3890 - dense_regress_td_loss: 0.1066 - dense_class_td_acc: 0.8887/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (1.343660). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "861/861 [==============================] - 93s 108ms/step - loss: 0.8156 - rpn_out_class_loss: 0.0322 - rpn_out_regress_loss: 0.0141 - dense_class_td_loss: 0.1428 - dense_regress_td_loss: 0.1694 - dense_class_td_acc: 0.9399\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Bootstrap : Using [0]lo:127.0.0.1<0> [1]eth0:172.17.0.2<0>\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO NET/IB : No device found.\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0> [1]eth0:172.17.0.2<0>\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Using network Socket\n",
      "NCCL version 2.7.8+cuda11.1\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 00/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 01/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 02/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 03/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 04/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 05/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 06/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 07/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 08/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 09/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 10/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 11/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 12/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 13/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 14/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 15/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 16/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 17/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 18/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 19/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 20/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 21/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 22/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 23/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 24/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 25/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 26/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 27/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 28/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 29/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 30/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Channel 31/32 :    0\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [1] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [2] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [3] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [4] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [5] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [6] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [7] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [8] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [9] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [10] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [11] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [12] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [13] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [14] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [15] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [16] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [17] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [18] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [19] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [20] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [21] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [22] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [23] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [24] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [25] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [26] -1/-1/-1->0->-1|-1->0->\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "1effd76581b5:2171:2199 [0] NCCL INFO comm 0x7fa2ac32a200 rank 0 nranks 1 cudaDev 0 busId 1000 - Init COMPLETE\n",
      "Doing validation at epoch 1(1-based index)...\n",
      "100%|█████████████████████████████████████████| 140/140 [00:07<00:00, 18.75it/s]\n",
      "==========================================================================================\n",
      "Class               AP                  precision           recall              RPN_recall          \n",
      "------------------------------------------------------------------------------------------\n",
      "noctuidae           0.6921              0.0380              0.8369              0.9929              \n",
      "------------------------------------------------------------------------------------------\n",
      "mAP@0.5 = 0.6921              \n",
      "Validation done!\n",
      "Epoch 2/12\n",
      "686/861 [======================>.......] - ETA: 17s - loss: 0.6818 - rpn_out_class_loss: 0.0207 - rpn_out_regress_loss: 0.0104 - dense_class_td_loss: 0.0950 - dense_regress_td_loss: 0.1140 - dense_class_td_acc: 0.9577^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/faster_rcnn\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/entrypoint/faster_rcnn.py\", line 12, in main\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py\", line 74, in <module>\n",
      "  File \"/home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/entrypoint/entrypoint.py\", line 294, in launch_job\n",
      "  File \"/home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py\", line 70, in main\n",
      "  File \"/usr/lib/python3.6/subprocess.py\", line 289, in call\n",
      "  File \"/home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/models/model_builder.py\", line 744, in train\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1039, in fit\n",
      "    return p.wait(timeout=timeout)\n",
      "  File \"/usr/lib/python3.6/subprocess.py\", line 1477, in wait\n",
      "    (pid, sts) = self._try_wait(0)\n",
      "  File \"/usr/lib/python3.6/subprocess.py\", line 1424, in _try_wait\n",
      "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
      "KeyboardInterrupt\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\", line 154, in fit_loop\n",
      "    outs = f(ins)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n",
      "    return self._call(inputs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n",
      "    fetched = self._callable_fn(*array_vals)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# run QAT training\n",
    "!faster_rcnn train --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_custom.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 10.2. Evaluation <a class=\"anchor\" id=\"head-10.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 10.3. Pruning <a class=\"anchor\" id=\"head-10.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!faster_rcnn prune --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18.epoch12.tlt \\\n",
    "           -o $USER_EXPERIMENT_DIR/data/faster_rcnn/model_1_pruned.tlt  \\\n",
    "           -eq union  \\\n",
    "           -pth 0.2 \\\n",
    "           -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 10.4. Retraining <a class=\"anchor\" id=\"head-10.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set enable_qat to True in retraining spec file to enable QAT\n",
    "!sed -i 's/enable_qat: False/enable_qat: True/' $SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n",
    "!cat $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!faster_rcnn train --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 10.5. Evaluation of the retrained model <a class=\"anchor\" id=\"head-10.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable the tensorrt evaluation config in spec file\n",
    "!TRT_LINES=$(grep -n 'trt_evaluation' $SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/^/#/g\\n' $(seq $TRT_LINES $((TRT_LINES+4))) | sed -i -f - $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do evaluation with .tlt model\n",
    "!faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 10.6. Inference of the retrained model <a class=\"anchor\" id=\"head-10.6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable the tensorrt inference config in spec file\n",
    "!TRT_LINES=$(grep -n 'trt_inference' $SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/^/#/g\\n' $(seq $TRT_LINES $((TRT_LINES+4))) | sed -i -f - $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do inference with .tlt model\n",
    "!faster_rcnn inference --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the sample images\n",
    "OUTPUT_PATH = 'data/faster_rcnn/inference_results_imgs_retrain' # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 3 # number of columns in the visualizer grid.\n",
    "IMAGES = 9 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 10.7. Deployment of the QAT model <a class=\"anchor\" id=\"head-10.7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export in INT8 mode(generate calibration cache file).\n",
    "# No need for calibration dataset for QAT model INT8 export\n",
    "!rm $USER_EXPERIMENT_DIR/data/faster_rcnn/cal.bin\n",
    "!if [ -f $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_int8_qat.etlt ]; then rm $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_int8_qat.etlt; fi\n",
    "!faster_rcnn export --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain.epoch12.tlt  \\\n",
    "                        -o $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_int8_qat.etlt \\\n",
    "                        -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt \\\n",
    "                        -k $KEY \\\n",
    "                        --data_type int8 \\\n",
    "                        --cal_cache_file $USER_EXPERIMENT_DIR/data/faster_rcnn/cal.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorRT engine(INT8).\n",
    "# Make sure your GPU type supports the INT8 data type before running this cell.\n",
    "!CUDA_VISIBLE_DEVICES=$GPU_INDEX tlt-converter -k $KEY  \\\n",
    "               -d 3,384,1248 \\\n",
    "               -o NMS \\\n",
    "               -c $USER_EXPERIMENT_DIR/data/faster_rcnn/cal.bin \\\n",
    "               -e $USER_EXPERIMENT_DIR/data/faster_rcnn/trt.int8.engine \\\n",
    "               -b 8 \\\n",
    "               -m 4 \\\n",
    "               -t int8 \\\n",
    "               -i nchw \\\n",
    "               $USER_EXPERIMENT_DIR/data/faster_rcnn/frcnn_kitti_resnet18_retrain_int8_qat.etlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exported model and converted TensorRT engine:')\n",
    "print('------------')\n",
    "!ls -lht $USER_EXPERIMENT_DIR/data/faster_rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do inference with TensorRT on the generated TensorRT engine\n",
    "# Please go to $USER_EXPERIMENT_DIR/data/faster_rcnn/inference_results_imgs_retrain to see the visualizations.\n",
    "!TRT_LINES=$(grep -n 'trt_inference' $SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/#//g\\n' $(seq $TRT_LINES $((TRT_LINES+4))) | sed -i -f - $SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n",
    "!faster_rcnn inference --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the sample images from TensorRT inference.\n",
    "OUTPUT_PATH = 'data/faster_rcnn/inference_results_imgs_retrain' # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 3 # number of columns in the visualizer grid.\n",
    "IMAGES = 9 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing evaluation with the generated TensorRT engine\n",
    "# compare the mAP below with that of `evaluate` with retrained tlt model\n",
    "!TRT_LINES=$(grep -n 'trt_evaluation' $SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/#//g\\n' $(seq $TRT_LINES $((TRT_LINES+4))) | sed -i -f - $SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n",
    "!faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
